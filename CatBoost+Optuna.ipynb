{
 "cells": [
  {
   "cell_type": "code",
   "id": "1702c22a0dcca05a",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-02T15:46:33.944336Z",
     "start_time": "2024-06-02T15:46:30.877218Z"
    }
   },
   "source": [
    "import catboost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pymorphy2\n",
    "import os\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, classification_report, accuracy_score\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import warnings\n",
    "from sklearn.cluster import DBSCAN\n",
    "import optuna\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T15:46:34.002242Z",
     "start_time": "2024-06-02T15:46:33.946619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загрузка данных\n",
    "train_groups = pd.read_csv('train_groups.csv')\n",
    "test_groups = pd.read_csv('test_groups.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "docs_titles = pd.read_csv('docs_titles.tsv', sep='\\t')"
   ],
   "id": "40a1ad5d2fac7268",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T15:46:34.010102Z",
     "start_time": "2024-06-02T15:46:34.003149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Объединение заголовков с данными групп\n",
    "train_data = train_groups.merge(docs_titles, on='doc_id')\n",
    "test_data = test_groups.merge(docs_titles, on='doc_id', how='left')"
   ],
   "id": "61c828b8a6dde8b6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T15:46:34.015068Z",
     "start_time": "2024-06-02T15:46:34.010956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Проверка наличия пропусков и их заполнение\n",
    "train_data['title'].fillna('', inplace=True)\n",
    "test_data['title'].fillna('', inplace=True)"
   ],
   "id": "ac4c61c602fe1942",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T15:46:51.194258Z",
     "start_time": "2024-06-02T15:46:34.016657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Предобработка данных\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('russian')) | set(stopwords.words('english'))\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  # Удаление HTML-тегов\n",
    "    text = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', text.lower())  # Удаление спецсимволов\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stop_words and not token.isdigit()]\n",
    "    tokens = [morph.parse(word)[0].normal_form for word in tokens]\n",
    "    return ' '.join(tokens)  # Изменено на возврат строки\n",
    "\n",
    "train_data['title_processed'] = train_data['title'].apply(preprocess_text)\n",
    "test_data['title_processed'] = test_data['title'].apply(preprocess_text)"
   ],
   "id": "f39081e1caf00989",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/taniyashuba/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/taniyashuba/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/taniyashuba/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T16:04:07.357143Z",
     "start_time": "2024-06-02T15:46:51.194991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Векторизация с помощью BERT\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "\n",
    "train_data['title_embeddings'] = train_data['title_processed'].apply(lambda x: get_bert_embeddings(x))\n",
    "test_data['title_embeddings'] = test_data['title_processed'].apply(lambda x: get_bert_embeddings(x))"
   ],
   "id": "f7b0c16a5411365f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T16:04:07.537558Z",
     "start_time": "2024-06-02T16:04:07.359299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Создание фичей\n",
    "def embeddings_to_features(data, column_prefix):\n",
    "    embeddings = np.stack(data[column_prefix + '_embeddings'].values)\n",
    "    feature_names = [f\"{column_prefix}_embedding_{i}\" for i in range(embeddings.shape[1])]\n",
    "    features_df = pd.DataFrame(embeddings, columns=feature_names, index=data.index)\n",
    "    return features_df\n",
    "\n",
    "train_features = embeddings_to_features(train_data, 'title')\n",
    "test_features = embeddings_to_features(test_data, 'title')\n",
    "\n",
    "def add_new_features(data):\n",
    "    data['title_length'] = data['title'].apply(lambda x: len(x.split()))\n",
    "    data['unique_words'] = data['title_processed'].apply(lambda x: len(set(x.split())))\n",
    "    return data\n",
    "\n",
    "train_data = add_new_features(train_data)\n",
    "test_data = add_new_features(test_data)"
   ],
   "id": "c64ce426b8ae92de",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T16:04:07.543632Z",
     "start_time": "2024-06-02T16:04:07.538692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Косинусные сходства Tfidf\n",
    "def vectorize_group(group):\n",
    "    vectorizer = TfidfVectorizer(tokenizer=preprocess_text)\n",
    "    vectors = vectorizer.fit_transform(group['title'])\n",
    "    return vectors\n",
    "\n",
    "def cosine_matrix_group(group):\n",
    "    tfidf_matrix = vectorize_group(group)\n",
    "    cosine_matrix = cosine_similarity(tfidf_matrix)\n",
    "    return cosine_matrix\n",
    "\n",
    "def calc_cosine_similarity(data_grouped, count=10):\n",
    "    similarity_features_list = []\n",
    "    for name, group in tqdm(data_grouped, desc=\"Processing groups\"):\n",
    "        cosine_matrix = cosine_matrix_group(group)\n",
    "        for k, (idx, row) in enumerate(group.iterrows()):\n",
    "            similarities = []\n",
    "            for j in range(len(group)):\n",
    "                if k == j:\n",
    "                    continue\n",
    "                similarities.append(cosine_matrix[k, j])\n",
    "            top_similarities = sorted(similarities, reverse=True)[:count]\n",
    "            similarity_record = [row['pair_id']] + top_similarities\n",
    "            similarity_features_list.append(similarity_record)\n",
    "    similarity_columns = ['pair_id'] + [f'top_{i + 1}_similarity' for i in range(count)]\n",
    "    similarity_features = pd.DataFrame(similarity_features_list, columns=similarity_columns)\n",
    "    return similarity_features"
   ],
   "id": "463b1b3b42b9bfb1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T16:04:07.547544Z",
     "start_time": "2024-06-02T16:04:07.544541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Кластеризация\n",
    "def clustering_features(data_grouped, eps=0.5, min_samples=5, metric='cosine'):\n",
    "    clustering_features_list = []\n",
    "    for name, group in tqdm(data_grouped, desc=\"Processing groups\"):\n",
    "        cosine_matrix = cosine_matrix_group(group)\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples, metric=metric).fit(cosine_matrix)\n",
    "        cluster_labels = dbscan.labels_\n",
    "        for k, (idx, row) in enumerate(group.iterrows()):\n",
    "            clustering_record = [row['pair_id'], cluster_labels[k]]\n",
    "            clustering_features_list.append(clustering_record)\n",
    "    clustering_columns = ['pair_id', 'cluster']\n",
    "    clustering_features = pd.DataFrame(clustering_features_list, columns=clustering_columns)\n",
    "    return clustering_features"
   ],
   "id": "80821a3e6d8df45d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T16:04:45.720891Z",
     "start_time": "2024-06-02T16:04:07.548509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Объединение данных и фичей в датасет\n",
    "train_data_grouped = train_data.groupby('group_id')\n",
    "test_data_grouped = test_data.groupby('group_id')\n",
    "\n",
    "train_similarity_features = calc_cosine_similarity(train_data_grouped)\n",
    "train_clustering_features = clustering_features(train_data_grouped)\n",
    "\n",
    "test_similarity_features = calc_cosine_similarity(test_data_grouped)\n",
    "test_clustering_features = clustering_features(test_data_grouped)\n",
    "\n",
    "train_similarity_features = train_similarity_features.fillna(0)\n",
    "test_similarity_features = test_similarity_features.fillna(0)\n",
    "\n",
    "train_data = train_data.merge(train_similarity_features, on=['pair_id'])\n",
    "train_data = train_data.merge(train_clustering_features, on=['pair_id'])\n",
    "\n",
    "test_data = test_data.merge(test_similarity_features, on=['pair_id'])\n",
    "test_data = test_data.merge(test_clustering_features, on=['pair_id'])\n",
    "\n",
    "train_data = pd.concat([train_data, train_features], axis=1)\n",
    "test_data = pd.concat([test_data, test_features], axis=1)\n",
    "\n",
    "drop_columns = ['title_embeddings']\n",
    "train_data.drop(columns=[col for col in drop_columns if col in train_data.columns], inplace=True)\n",
    "test_data.drop(columns=[col for col in drop_columns if col in test_data.columns], inplace=True)\n",
    "\n",
    "X_train = train_data.drop(columns=['doc_id', 'pair_id', 'group_id', 'target', 'title', 'title_processed'], axis=1)\n",
    "y_train = train_data['target']\n",
    "\n",
    "X_test = test_data.drop(columns=['doc_id', 'pair_id', 'group_id', 'title', 'title_processed'], axis=1)"
   ],
   "id": "81892a1b816126ff",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing groups: 100%|██████████| 129/129 [00:07<00:00, 17.30it/s]\n",
      "Processing groups: 100%|██████████| 129/129 [00:07<00:00, 16.22it/s]\n",
      "Processing groups: 100%|██████████| 180/180 [00:10<00:00, 16.62it/s]\n",
      "Processing groups: 100%|██████████| 180/180 [00:11<00:00, 15.44it/s]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T16:04:45.857709Z",
     "start_time": "2024-06-02T16:04:45.722864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Скейлинг данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "id": "69440fcad6563d56",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T16:04:46.286718Z",
     "start_time": "2024-06-02T16:04:45.858680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Подбор гиперпараметров для CatBoost с использованием Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-1, 10),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'random_strength': trial.suggest_loguniform('random_strength', 1e-3, 10),\n",
    "        'bagging_temperature': trial.suggest_loguniform('bagging_temperature', 1e-3, 10),\n",
    "        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n",
    "        'od_wait': trial.suggest_int('od_wait', 10, 50),\n",
    "    }\n",
    "\n",
    "    train_pool = Pool(X_train_scaled, y_train)\n",
    "    cv_results = catboost.cv(\n",
    "        train_pool,\n",
    "        params,\n",
    "        fold_count=5,\n",
    "        early_stopping_rounds=50,\n",
    "        stratified=True,\n",
    "        verbose=False,\n",
    "        plot=False\n",
    "    )\n",
    "\n",
    "    return cv_results['test-F1-mean'].max()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50, n_jobs=-1)\n",
    "\n",
    "best_params = study.best_params"
   ],
   "id": "f75d0cf9b89f5fec",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-02 19:04:45,861] A new study created in memory with name: no-name-b6e1eec6-48ed-41ee-8e8c-8e9946d86ddf\n",
      "[W 2024-06-02 19:04:45,878] Trial 0 failed with parameters: {'iterations': 165, 'depth': 6, 'learning_rate': 0.003951491874899117, 'l2_leaf_reg': 9.34040746386525, 'border_count': 70, 'random_strength': 6.902129825165415, 'bagging_temperature': 0.008493201002157516, 'od_type': 'Iter', 'od_wait': 25} because of the following error: CatBoostError('Parameter loss_function should be specified for cross-validation').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/87/d35_l8056xbbpvj6g4knhvsm0000gn/T/ipykernel_46918/3805093963.py\", line 16, in objective\n",
      "    cv_results = catboost.cv(\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/catboost/core.py\", line 6803, in cv\n",
      "    raise CatBoostError(\"Parameter loss_function should be specified for cross-validation\")\n",
      "_catboost.CatBoostError: Parameter loss_function should be specified for cross-validation\n",
      "[W 2024-06-02 19:04:45,888] Trial 1 failed with parameters: {'iterations': 564, 'depth': 5, 'learning_rate': 0.01288029682714703, 'l2_leaf_reg': 4.865292294589945, 'border_count': 197, 'random_strength': 0.06607838125709221, 'bagging_temperature': 0.0060389383832800516, 'od_type': 'Iter', 'od_wait': 12} because of the following error: CatBoostError('Parameter loss_function should be specified for cross-validation').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/87/d35_l8056xbbpvj6g4knhvsm0000gn/T/ipykernel_46918/3805093963.py\", line 16, in objective\n",
      "    cv_results = catboost.cv(\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/catboost/core.py\", line 6803, in cv\n",
      "    raise CatBoostError(\"Parameter loss_function should be specified for cross-validation\")\n",
      "_catboost.CatBoostError: Parameter loss_function should be specified for cross-validation\n",
      "[W 2024-06-02 19:04:45,893] Trial 2 failed with parameters: {'iterations': 726, 'depth': 8, 'learning_rate': 0.014082049524037712, 'l2_leaf_reg': 2.247504032772564, 'border_count': 206, 'random_strength': 1.5755794242335808, 'bagging_temperature': 0.2034099840572812, 'od_type': 'IncToDec', 'od_wait': 27} because of the following error: CatBoostError('Parameter loss_function should be specified for cross-validation').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/87/d35_l8056xbbpvj6g4knhvsm0000gn/T/ipykernel_46918/3805093963.py\", line 16, in objective\n",
      "    cv_results = catboost.cv(\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/catboost/core.py\", line 6803, in cv\n",
      "    raise CatBoostError(\"Parameter loss_function should be specified for cross-validation\")\n",
      "_catboost.CatBoostError: Parameter loss_function should be specified for cross-validation\n",
      "[W 2024-06-02 19:04:45,900] Trial 0 failed with value None.\n",
      "[W 2024-06-02 19:04:45,901] Trial 1 failed with value None.\n",
      "[W 2024-06-02 19:04:45,905] Trial 3 failed with parameters: {'iterations': 968, 'depth': 10, 'learning_rate': 0.06983972419412543, 'l2_leaf_reg': 1.0421168177671867, 'border_count': 46, 'random_strength': 9.602496971704216, 'bagging_temperature': 5.668651123461854, 'od_type': 'Iter', 'od_wait': 35} because of the following error: CatBoostError('Parameter loss_function should be specified for cross-validation').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/87/d35_l8056xbbpvj6g4knhvsm0000gn/T/ipykernel_46918/3805093963.py\", line 16, in objective\n",
      "    cv_results = catboost.cv(\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/catboost/core.py\", line 6803, in cv\n",
      "    raise CatBoostError(\"Parameter loss_function should be specified for cross-validation\")\n",
      "_catboost.CatBoostError: Parameter loss_function should be specified for cross-validation\n",
      "[W 2024-06-02 19:04:45,909] Trial 4 failed with parameters: {'iterations': 245, 'depth': 4, 'learning_rate': 0.003391528805808375, 'l2_leaf_reg': 0.43643915194848293, 'border_count': 125, 'random_strength': 1.048834386810201, 'bagging_temperature': 0.003093422701047789, 'od_type': 'Iter', 'od_wait': 18} because of the following error: CatBoostError('Parameter loss_function should be specified for cross-validation').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/87/d35_l8056xbbpvj6g4knhvsm0000gn/T/ipykernel_46918/3805093963.py\", line 16, in objective\n",
      "    cv_results = catboost.cv(\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/catboost/core.py\", line 6803, in cv\n",
      "    raise CatBoostError(\"Parameter loss_function should be specified for cross-validation\")\n",
      "_catboost.CatBoostError: Parameter loss_function should be specified for cross-validation\n",
      "[W 2024-06-02 19:04:45,913] Trial 5 failed with parameters: {'iterations': 679, 'depth': 7, 'learning_rate': 0.00881310441560355, 'l2_leaf_reg': 2.2090411689412424, 'border_count': 158, 'random_strength': 0.012153986491468522, 'bagging_temperature': 5.660352937756892, 'od_type': 'IncToDec', 'od_wait': 48} because of the following error: CatBoostError('Parameter loss_function should be specified for cross-validation').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/87/d35_l8056xbbpvj6g4knhvsm0000gn/T/ipykernel_46918/3805093963.py\", line 16, in objective\n",
      "    cv_results = catboost.cv(\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/catboost/core.py\", line 6803, in cv\n",
      "    raise CatBoostError(\"Parameter loss_function should be specified for cross-validation\")\n",
      "_catboost.CatBoostError: Parameter loss_function should be specified for cross-validation\n",
      "[W 2024-06-02 19:04:45,917] Trial 6 failed with parameters: {'iterations': 340, 'depth': 4, 'learning_rate': 0.07933491286904949, 'l2_leaf_reg': 6.3149371681678925, 'border_count': 46, 'random_strength': 0.01844488863374651, 'bagging_temperature': 0.008965429635785335, 'od_type': 'Iter', 'od_wait': 15} because of the following error: CatBoostError('Parameter loss_function should be specified for cross-validation').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/87/d35_l8056xbbpvj6g4knhvsm0000gn/T/ipykernel_46918/3805093963.py\", line 16, in objective\n",
      "    cv_results = catboost.cv(\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/catboost/core.py\", line 6803, in cv\n",
      "    raise CatBoostError(\"Parameter loss_function should be specified for cross-validation\")\n",
      "_catboost.CatBoostError: Parameter loss_function should be specified for cross-validation\n",
      "[W 2024-06-02 19:04:45,930] Trial 6 failed with value None.\n",
      "[W 2024-06-02 19:04:45,924] Trial 8 failed with parameters: {'iterations': 527, 'depth': 9, 'learning_rate': 0.001212761358068269, 'l2_leaf_reg': 0.6043170613436244, 'border_count': 195, 'random_strength': 2.4187850936374238, 'bagging_temperature': 0.006035240843971812, 'od_type': 'IncToDec', 'od_wait': 11} because of the following error: CatBoostError('Parameter loss_function should be specified for cross-validation').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/87/d35_l8056xbbpvj6g4knhvsm0000gn/T/ipykernel_46918/3805093963.py\", line 16, in objective\n",
      "    cv_results = catboost.cv(\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/catboost/core.py\", line 6803, in cv\n",
      "    raise CatBoostError(\"Parameter loss_function should be specified for cross-validation\")\n",
      "_catboost.CatBoostError: Parameter loss_function should be specified for cross-validation\n",
      "[W 2024-06-02 19:04:45,928] Trial 9 failed with parameters: {'iterations': 795, 'depth': 7, 'learning_rate': 0.001578838392001418, 'l2_leaf_reg': 0.48941353277352734, 'border_count': 193, 'random_strength': 0.1785580403605337, 'bagging_temperature': 0.02246420214795434, 'od_type': 'IncToDec', 'od_wait': 16} because of the following error: CatBoostError('Parameter loss_function should be specified for cross-validation').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/87/d35_l8056xbbpvj6g4knhvsm0000gn/T/ipykernel_46918/3805093963.py\", line 16, in objective\n",
      "    cv_results = catboost.cv(\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/catboost/core.py\", line 6803, in cv\n",
      "    raise CatBoostError(\"Parameter loss_function should be specified for cross-validation\")\n",
      "_catboost.CatBoostError: Parameter loss_function should be specified for cross-validation\n",
      "[W 2024-06-02 19:04:45,928] Trial 2 failed with value None.\n",
      "[W 2024-06-02 19:04:45,929] Trial 3 failed with value None.\n",
      "[W 2024-06-02 19:04:45,929] Trial 4 failed with value None.\n",
      "[W 2024-06-02 19:04:45,930] Trial 5 failed with value None.\n",
      "[W 2024-06-02 19:04:45,920] Trial 7 failed with parameters: {'iterations': 273, 'depth': 10, 'learning_rate': 0.001585016915076548, 'l2_leaf_reg': 0.10985488364257238, 'border_count': 125, 'random_strength': 0.0011650114242000118, 'bagging_temperature': 0.003706767832083506, 'od_type': 'IncToDec', 'od_wait': 32} because of the following error: CatBoostError('Parameter loss_function should be specified for cross-validation').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/87/d35_l8056xbbpvj6g4knhvsm0000gn/T/ipykernel_46918/3805093963.py\", line 16, in objective\n",
      "    cv_results = catboost.cv(\n",
      "  File \"/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/catboost/core.py\", line 6803, in cv\n",
      "    raise CatBoostError(\"Parameter loss_function should be specified for cross-validation\")\n",
      "_catboost.CatBoostError: Parameter loss_function should be specified for cross-validation\n",
      "[W 2024-06-02 19:04:45,931] Trial 8 failed with value None.\n",
      "[W 2024-06-02 19:04:45,932] Trial 9 failed with value None.\n",
      "[W 2024-06-02 19:04:45,933] Trial 7 failed with value None.\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "Parameter loss_function should be specified for cross-validation",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCatBoostError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 29\u001B[0m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest-F1-mean\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmax()\n\u001B[1;32m     28\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 29\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m best_params \u001B[38;5;241m=\u001B[39m study\u001B[38;5;241m.\u001B[39mbest_params\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/optuna/study/study.py:451\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[1;32m    349\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    350\u001B[0m     func: ObjectiveFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    357\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    358\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    359\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[1;32m    360\u001B[0m \n\u001B[1;32m    361\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    449\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 451\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    452\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    453\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    454\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    456\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    458\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    459\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    461\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/optuna/study/_optimize.py:99\u001B[0m, in \u001B[0;36m_optimize\u001B[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m     97\u001B[0m                     \u001B[38;5;66;03m# Raise if exception occurred in executing the completed futures.\u001B[39;00m\n\u001B[1;32m     98\u001B[0m                     \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m completed:\n\u001B[0;32m---> 99\u001B[0m                         \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    101\u001B[0m                 futures\u001B[38;5;241m.\u001B[39madd(\n\u001B[1;32m    102\u001B[0m                     executor\u001B[38;5;241m.\u001B[39msubmit(\n\u001B[1;32m    103\u001B[0m                         _optimize_sequential,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    114\u001B[0m                     )\n\u001B[1;32m    115\u001B[0m                 )\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:438\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    436\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    437\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 438\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    440\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[1;32m    442\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:390\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    389\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 390\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    391\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    392\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    393\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py:52\u001B[0m, in \u001B[0;36m_WorkItem.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 52\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuture\u001B[38;5;241m.\u001B[39mset_exception(exc)\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/optuna/study/_optimize.py:159\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[1;32m    156\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 159\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    161\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[1;32m    164\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/optuna/study/_optimize.py:247\u001B[0m, in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    240\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    242\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    243\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[1;32m    244\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    245\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[1;32m    246\u001B[0m ):\n\u001B[0;32m--> 247\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[1;32m    248\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/optuna/study/_optimize.py:196\u001B[0m, in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[1;32m    195\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 196\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    197\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    198\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[1;32m    199\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[0;32mIn[12], line 16\u001B[0m, in \u001B[0;36mobjective\u001B[0;34m(trial)\u001B[0m\n\u001B[1;32m      3\u001B[0m params \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124miterations\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_int(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124miterations\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m1000\u001B[39m),\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdepth\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_int(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdepth\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m10\u001B[39m),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mod_wait\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_int(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mod_wait\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m50\u001B[39m),\n\u001B[1;32m     13\u001B[0m }\n\u001B[1;32m     15\u001B[0m train_pool \u001B[38;5;241m=\u001B[39m Pool(X_train_scaled, y_train)\n\u001B[0;32m---> 16\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcatboost\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_pool\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfold_count\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstratified\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43mplot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[1;32m     24\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest-F1-mean\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmax()\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/catboost/core.py:6803\u001B[0m, in \u001B[0;36mcv\u001B[0;34m(pool, params, dtrain, iterations, num_boost_round, fold_count, nfold, inverted, partition_random_seed, seed, shuffle, logging_level, stratified, as_pandas, metric_period, verbose, verbose_eval, plot, plot_file, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, metric_update_interval, folds, type, return_models, log_cout, log_cerr)\u001B[0m\n\u001B[1;32m   6799\u001B[0m metric_period, verbose, logging_level \u001B[38;5;241m=\u001B[39m _process_verbose(\n\u001B[1;32m   6800\u001B[0m     metric_period, verbose, logging_level, verbose_eval)\n\u001B[1;32m   6802\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss_function\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m params:\n\u001B[0;32m-> 6803\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CatBoostError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mParameter loss_function should be specified for cross-validation\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(v \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m [fold_count, nfold]) \u001B[38;5;129;01mand\u001B[39;00m folds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   6806\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CatBoostError(\n\u001B[1;32m   6807\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mif folds is not None, then all of fold_count, shuffle, partition_random_seed, inverted are None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   6808\u001B[0m     )\n",
      "\u001B[0;31mCatBoostError\u001B[0m: Parameter loss_function should be specified for cross-validation"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T16:04:46.288001Z",
     "start_time": "2024-06-02T16:04:46.287934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Обучение CatBoost с лучшими параметрами на полном наборе данных\n",
    "final_cat_model = CatBoostClassifier(**best_params)\n",
    "final_cat_model.fit(X_train_scaled, y_train)"
   ],
   "id": "b390bf64053c14a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Настройка параметров мета-модели\n",
    "meta_params = {'C': [0.1, 1, 10]}\n",
    "meta_grid = GridSearchCV(LogisticRegression(), meta_params, cv=5, scoring='f1', n_jobs=-1)\n",
    "meta_grid.fit(X_train_scaled, y_train)\n",
    "best_meta = meta_grid.best_estimator_"
   ],
   "id": "985aef8e6b13656d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Настройка параметров базовых моделей\n",
    "knn_params = {'n_neighbors': [3, 5, 7, 10]}\n",
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, scoring='f1', n_jobs=-1)\n",
    "knn_grid.fit(X_train_scaled, y_train)\n",
    "best_knn = knn_grid.best_estimator_\n",
    "\n",
    "rf_params = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20, 30]}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(), rf_params, cv=5, scoring='f1', n_jobs=-1)\n",
    "rf_grid.fit(X_train_scaled, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n",
    "svc_params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "svc_grid = GridSearchCV(SVC(probability=True), svc_params, cv=5, scoring='f1', n_jobs=-1)\n",
    "svc_grid.fit(X_train_scaled, y_train)\n",
    "best_svc = svc_grid.best_estimator_"
   ],
   "id": "f9b283c05a5bfa21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Стекинг\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('knn', best_knn),\n",
    "        ('rf', best_rf),\n",
    "        ('svc', best_svc),\n",
    "        ('cat', final_cat_model)\n",
    "    ],\n",
    "    final_estimator=best_meta,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "stacking_model.fit(X_train_scaled, y_train)"
   ],
   "id": "ce371c8b512e4d9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Предсказание и сохранение результатов\n",
    "test_predictions = stacking_model.predict(X_test_scaled)"
   ],
   "id": "2357c7c418e63ca0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Сохранение результатов\n",
    "submission = test_groups[['pair_id']].copy()\n",
    "submission['target'] = test_predictions\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Файл с предсказаниями создан: submission.csv')"
   ],
   "id": "58538f4908b8b21b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Важность признаков\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = final_cat_model.get_feature_importance(type='PredictionValuesChange')\n",
    "feature_importances = pd.Series(importances, index=X_train.columns).sort_values()[-15:]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importances.index, feature_importances.values)\n",
    "plt.title('CatBoost Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.show()\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
