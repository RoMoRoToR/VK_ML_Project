{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#Загрузка моделей и библиотек"
   ],
   "metadata": {
    "id": "R8Igddv6CM66"
   },
   "id": "R8Igddv6CM66"
  },
  {
   "cell_type": "code",
   "source": [
    "import tokenizer\n",
    "!pip install catboost\n",
    "!pip install pymorphy2"
   ],
   "metadata": {
    "collapsed": true,
    "id": "gW_g1cuiifMO",
    "ExecuteTime": {
     "end_time": "2024-06-01T13:17:13.903258Z",
     "start_time": "2024-06-01T13:17:10.456293Z"
    }
   },
   "id": "gW_g1cuiifMO",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in ./venv/lib/python3.9/site-packages (1.2.5)\r\n",
      "Requirement already satisfied: graphviz in ./venv/lib/python3.9/site-packages (from catboost) (0.20.3)\r\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.9/site-packages (from catboost) (3.9.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.0 in ./venv/lib/python3.9/site-packages (from catboost) (1.26.4)\r\n",
      "Requirement already satisfied: pandas>=0.24 in ./venv/lib/python3.9/site-packages (from catboost) (2.2.2)\r\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.9/site-packages (from catboost) (1.11.0)\r\n",
      "Requirement already satisfied: plotly in ./venv/lib/python3.9/site-packages (from catboost) (5.22.0)\r\n",
      "Requirement already satisfied: six in ./venv/lib/python3.9/site-packages (from catboost) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2024.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (4.52.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (24.0)\r\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (10.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (3.1.2)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (6.4.0)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./venv/lib/python3.9/site-packages (from plotly->catboost) (8.3.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.19.0)\r\n",
      "Requirement already satisfied: pymorphy2 in ./venv/lib/python3.9/site-packages (0.9.1)\r\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in ./venv/lib/python3.9/site-packages (from pymorphy2) (0.7.2)\r\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in ./venv/lib/python3.9/site-packages (from pymorphy2) (2.4.417127.4579844)\r\n",
      "Requirement already satisfied: docopt>=0.6 in ./venv/lib/python3.9/site-packages (from pymorphy2) (0.6.2)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "901132e79c82f040",
   "metadata": {
    "collapsed": true,
    "id": "901132e79c82f040",
    "ExecuteTime": {
     "end_time": "2024-06-01T13:17:21.178792Z",
     "start_time": "2024-06-01T13:17:13.906437Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pymorphy2\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.cluster import DBSCAN\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Загрузка данных"
   ],
   "metadata": {
    "id": "mW6VWhQGCVfc"
   },
   "id": "mW6VWhQGCVfc"
  },
  {
   "metadata": {
    "id": "dcd259dbdd5e5cdd",
    "ExecuteTime": {
     "end_time": "2024-06-01T13:17:21.234202Z",
     "start_time": "2024-06-01T13:17:21.179885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загрузка данных\n",
    "train_groups = pd.read_csv('train_groups.csv')\n",
    "test_groups = pd.read_csv('test_groups.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "docs_titles = pd.read_csv('docs_titles.tsv', sep='\\t')"
   ],
   "id": "dcd259dbdd5e5cdd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "id": "211e55804f9f14e9",
    "ExecuteTime": {
     "end_time": "2024-06-01T13:17:21.245137Z",
     "start_time": "2024-06-01T13:17:21.235065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Объединение заголовков с данными групп\n",
    "train_data = train_groups.merge(docs_titles, on='doc_id')\n",
    "test_data = test_groups.merge(docs_titles, on='doc_id', how='left')"
   ],
   "id": "211e55804f9f14e9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# Просмотр пропусков\n",
    "train_data.isna().sum(), test_data.isna().sum()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "diC4wvt9rW3O",
    "outputId": "e7f271a1-0886-4911-feba-855347fc36c9",
    "ExecuteTime": {
     "end_time": "2024-06-01T13:17:21.253158Z",
     "start_time": "2024-06-01T13:17:21.247254Z"
    }
   },
   "id": "diC4wvt9rW3O",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pair_id      0\n",
       " group_id     0\n",
       " doc_id       0\n",
       " target       0\n",
       " title       16\n",
       " dtype: int64,\n",
       " pair_id      0\n",
       " group_id     0\n",
       " doc_id       0\n",
       " title       92\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "id": "c1a03e30037f5f40",
    "ExecuteTime": {
     "end_time": "2024-06-01T13:17:21.257859Z",
     "start_time": "2024-06-01T13:17:21.254079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Обработка отсутствующих значений\n",
    "train_data['title'].fillna('', inplace=True)\n",
    "test_data['title'].fillna('', inplace=True)"
   ],
   "id": "c1a03e30037f5f40",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Предобработка данных"
   ],
   "metadata": {
    "id": "VNibqmm-CZHf"
   },
   "id": "VNibqmm-CZHf"
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "3d0f7e2e523b5231",
    "ExecuteTime": {
     "end_time": "2024-06-01T13:17:21.666974Z",
     "start_time": "2024-06-01T13:17:21.258764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загрузка данных для NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Стоп-слова и шум\n",
    "stop_words = set(stopwords.words('russian')) | set(stopwords.words('english'))\n",
    "\n",
    "# Пробуем стеммер или леммер\n",
    "stemmer = SnowballStemmer(\"russian\")\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ],
   "id": "3d0f7e2e523b5231",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/taniyashuba/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/taniyashuba/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/taniyashuba/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "id": "b882508403a74291",
    "ExecuteTime": {
     "end_time": "2024-06-01T13:17:39.383241Z",
     "start_time": "2024-06-01T13:17:21.669117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Токенизация + лемматизация/стемминг текста\n",
    "    \"\"\"\n",
    "    text = re.sub(r'<.*?>', '', text)  # Удаление HTML-тегов\n",
    "    text = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', text.lower())  # Удаление спецсимволов\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stop_words and not token.isdigit()]\n",
    "    tokens = [morph.parse(word)[0].normal_form for word in tokens]  # Лемматизация\n",
    "    return tokens\n",
    "\n",
    "train_data['title_processed'] = train_data['title'].apply(preprocess_text)\n",
    "test_data['title_processed'] = test_data['title'].apply(preprocess_text)"
   ],
   "id": "b882508403a74291",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Юзанье Word2wec",
   "id": "ce7c19ad3d833367"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:17:58.494669Z",
     "start_time": "2024-06-01T13:17:39.384019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "w2v_model = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "\n",
    "def get_w2v_embeddings(tokens):\n",
    "    vectors = [w2v_model[word] for word in tokens if word in w2v_model]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(w2v_model.vector_size)\n",
    "\n",
    "train_data['w2v_embeddings'] = train_data['title_processed'].apply(get_w2v_embeddings)\n",
    "test_data['w2v_embeddings'] = test_data['title_processed'].apply(get_w2v_embeddings)"
   ],
   "id": "d00189108288d51d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:17:58.515921Z",
     "start_time": "2024-06-01T13:17:58.495319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def embeddings_to_features(data, column_name):\n",
    "    embeddings = np.stack(data[column_name].values)\n",
    "    feature_names = [f\"{column_name}_{i}\" for i in range(embeddings.shape[1])]\n",
    "    return pd.DataFrame(embeddings, columns=feature_names, index=data.index)\n",
    "\n",
    "train_w2v_features = embeddings_to_features(train_data, 'w2v_embeddings')\n",
    "test_w2v_features = embeddings_to_features(test_data, 'w2v_embeddings')"
   ],
   "id": "58e716db3fb14c2a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Векторизация BERT"
   ],
   "metadata": {
    "id": "DUPVkQXoCi6I"
   },
   "id": "DUPVkQXoCi6I"
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "dcdfe60cee23b604",
    "ExecuteTime": {
     "end_time": "2024-06-01T14:45:12.490772Z",
     "start_time": "2024-06-01T14:45:11.471236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Векторизация с помощью BERT\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu()"
   ],
   "id": "b51c98a6efe1485f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T15:07:45.636789Z",
     "start_time": "2024-06-01T14:45:12.492443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Применение BERT для векторизации заголовков\n",
    "train_data['bert_embeddings'] = train_data['title'].apply(lambda x: get_bert_embeddings(x).numpy())\n",
    "test_data['bert_embeddings'] = test_data['title'].apply(lambda x: get_bert_embeddings(x).numpy())"
   ],
   "id": "a9a7275279a818af",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T23:22:22.405537Z",
     "start_time": "2024-06-01T23:22:22.402362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def embeddings_to_features_bert(data, column_name):\n",
    "    embeddings = np.vstack(data[column_name].values)\n",
    "    feature_names = [f\"{column_name}_{i}\" for i in range(embeddings.shape[1])]\n",
    "    return pd.DataFrame(embeddings, columns=feature_names, index=data.index)"
   ],
   "id": "8f44b9895e7aa3b5",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T23:22:23.131576Z",
     "start_time": "2024-06-01T23:22:23.081409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_bert_features = embeddings_to_features(train_data, 'bert_embeddings')\n",
    "test_bert_features = embeddings_to_features(test_data, 'bert_embeddings')"
   ],
   "id": "dcdfe60cee23b604",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bert_embeddings_embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'bert_embeddings_embeddings'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_bert_features \u001B[38;5;241m=\u001B[39m \u001B[43membeddings_to_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbert_embeddings\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m test_bert_features \u001B[38;5;241m=\u001B[39m embeddings_to_features(test_data, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbert_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[17], line 5\u001B[0m, in \u001B[0;36membeddings_to_features\u001B[0;34m(data, column_prefix)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21membeddings_to_features\u001B[39m(data, column_prefix):\n\u001B[1;32m      2\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m    Преобразуем эмбеддинги в фичи\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mstack(\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcolumn_prefix\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m_embeddings\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m      6\u001B[0m     feature_names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcolumn_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_embedding_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(embeddings\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m])]\n\u001B[1;32m      7\u001B[0m     features_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(embeddings, columns\u001B[38;5;241m=\u001B[39mfeature_names, index\u001B[38;5;241m=\u001B[39mdata\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3810\u001B[0m     ):\n\u001B[1;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'bert_embeddings_embeddings'"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Создание фичей"
   ],
   "metadata": {
    "id": "u-eLsZEzCoJM"
   },
   "id": "u-eLsZEzCoJM"
  },
  {
   "metadata": {
    "id": "e8c2bde5a6973eeb",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:19:51.821691Z",
     "start_time": "2024-06-01T23:19:51.729765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def embeddings_to_features(data, column_prefix):\n",
    "    \"\"\"\n",
    "    Преобразуем эмбеддинги в фичи\n",
    "    \"\"\"\n",
    "    embeddings = np.stack(data[column_prefix + '_embeddings'].values)\n",
    "    feature_names = [f\"{column_prefix}_embedding_{i}\" for i in range(embeddings.shape[1])]\n",
    "    features_df = pd.DataFrame(embeddings, columns=feature_names, index=data.index)\n",
    "    return features_df\n",
    "\n",
    "train_features = embeddings_to_features(train_data, 'title')\n",
    "test_features = embeddings_to_features(test_data, 'title')"
   ],
   "id": "e8c2bde5a6973eeb",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'title_embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'title_embeddings'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m     features_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(embeddings, columns\u001B[38;5;241m=\u001B[39mfeature_names, index\u001B[38;5;241m=\u001B[39mdata\u001B[38;5;241m.\u001B[39mindex)\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m features_df\n\u001B[0;32m---> 10\u001B[0m train_features \u001B[38;5;241m=\u001B[39m \u001B[43membeddings_to_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtitle\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m test_features \u001B[38;5;241m=\u001B[39m embeddings_to_features(test_data, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtitle\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[17], line 5\u001B[0m, in \u001B[0;36membeddings_to_features\u001B[0;34m(data, column_prefix)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21membeddings_to_features\u001B[39m(data, column_prefix):\n\u001B[1;32m      2\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m    Преобразуем эмбеддинги в фичи\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mstack(\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcolumn_prefix\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m_embeddings\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m      6\u001B[0m     feature_names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcolumn_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_embedding_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(embeddings\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m])]\n\u001B[1;32m      7\u001B[0m     features_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(embeddings, columns\u001B[38;5;241m=\u001B[39mfeature_names, index\u001B[38;5;241m=\u001B[39mdata\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3810\u001B[0m     ):\n\u001B[1;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'title_embeddings'"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "id": "36db76a1201238de",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:20:02.066696Z",
     "start_time": "2024-06-01T23:20:02.017639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_new_features(data):\n",
    "    \"\"\"\n",
    "    Добавляем новые признаки: длина заголовка и число уникальных слов\n",
    "    \"\"\"\n",
    "    data['title_length'] = data['title'].apply(lambda x: len(x.split()))\n",
    "    data['unique_words'] = data['title_processed'].apply(lambda x: len(set(x)))\n",
    "    return data\n",
    "\n",
    "train_data = add_new_features(train_data)\n",
    "test_data = add_new_features(test_data)"
   ],
   "id": "36db76a1201238de",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "def vectorize_group(group):\n",
    "    \"\"\"\n",
    "    Векторизуем группу документов с кастомным токенайзером\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(tokenizer=preprocess_text)\n",
    "    vectors = vectorizer.fit_transform(group['title'])\n",
    "    return vectors"
   ],
   "metadata": {
    "id": "gTq75O_sK58M",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:20:02.698538Z",
     "start_time": "2024-06-01T23:20:02.696402Z"
    }
   },
   "id": "gTq75O_sK58M",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "def data_to_tfidf(data_grouped):\n",
    "    \"\"\"\n",
    "    Создание tfidf матрицы для данных по группам\n",
    "    \"\"\"\n",
    "    tfidf_data = pd.DataFrame()\n",
    "    for name, group in tqdm(data_grouped, desc=\"Processing groups\"):\n",
    "        # Для каждой группы получаем векторное представление\n",
    "        tfidf_matrix = vectorize_group(group)\n",
    "        tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=[f'tfidf_{i}' for i in range(tfidf_matrix.shape[1])], index=group.index)\n",
    "        # Соединяем в df все группы\n",
    "        tfidf_data = pd.concat([tfidf_data, tfidf_df])\n",
    "    return tfidf_data"
   ],
   "metadata": {
    "id": "vxNwYOBA5BlG",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:20:03.236813Z",
     "start_time": "2024-06-01T23:20:03.234138Z"
    }
   },
   "id": "vxNwYOBA5BlG",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "def cosine_matrix_group(group):\n",
    "    \"\"\"\n",
    "    Вычисление матрицы косинусных расстояний для группы\n",
    "    \"\"\"\n",
    "    tfidf_matrix = vectorize_group(group)\n",
    "    cosine_matrix = cosine_similarity(tfidf_matrix)\n",
    "    return cosine_matrix"
   ],
   "metadata": {
    "id": "UQDLq8PQ5aqB",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:20:03.473373Z",
     "start_time": "2024-06-01T23:20:03.471027Z"
    }
   },
   "id": "UQDLq8PQ5aqB",
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "def calc_cosine_similarity(data_grouped, count=10):\n",
    "    \"\"\"\n",
    "    Возвращаем топ косинусных сходств для каждого документа группы\n",
    "    \"\"\"\n",
    "    similarity_features_list = []\n",
    "    for name, group in tqdm(data_grouped, desc=\"Processing groups\"):\n",
    "        cosine_matrix = cosine_matrix_group(group)\n",
    "        for k, (idx, row) in enumerate(group.iterrows()):\n",
    "            similarities = []\n",
    "            for j in range(len(group)):\n",
    "                if k == j:\n",
    "                    continue\n",
    "                similarities.append(cosine_matrix[k, j])\n",
    "            top_similarities = sorted(similarities, reverse=True)[:count]\n",
    "            similarity_record = [row['pair_id']] + top_similarities\n",
    "            similarity_features_list.append(similarity_record)\n",
    "    similarity_columns = ['pair_id'] + [f'top_{i+1}_similarity' for i in range(count)]\n",
    "    similarity_features = pd.DataFrame(similarity_features_list, columns=similarity_columns)\n",
    "    return similarity_features"
   ],
   "metadata": {
    "id": "Q5xUL97czxwE",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:20:04.005203Z",
     "start_time": "2024-06-01T23:20:03.998632Z"
    }
   },
   "id": "Q5xUL97czxwE",
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "def clustering_features(data_grouped, eps=0.5, min_samples=5, metric='cosine'):\n",
    "    \"\"\"\n",
    "    Возвращаем кластер для каждого документа группы\n",
    "    \"\"\"\n",
    "    clustering_features_list = []\n",
    "    for name, group in tqdm(data_grouped, desc=\"Processing groups\"):\n",
    "        cosine_matrix = cosine_matrix_group(group)\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples, metric=metric).fit(cosine_matrix)\n",
    "        cluster_labels = dbscan.labels_\n",
    "        for k, (idx, row) in enumerate(group.iterrows()):\n",
    "            clustering_record = [row['pair_id'], cluster_labels[k]]\n",
    "            clustering_features_list.append(clustering_record)\n",
    "    clustering_columns = ['pair_id', 'cluster']\n",
    "    clustering_features = pd.DataFrame(clustering_features_list, columns=clustering_columns)\n",
    "    return clustering_features"
   ],
   "metadata": {
    "id": "lCUlD0rm9S6t",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:20:04.621835Z",
     "start_time": "2024-06-01T23:20:04.618748Z"
    }
   },
   "id": "lCUlD0rm9S6t",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Объединение данных и фичей в датасет"
   ],
   "metadata": {
    "id": "U-6p30UFC2P2"
   },
   "id": "U-6p30UFC2P2"
  },
  {
   "cell_type": "code",
   "source": [
    "# Разбиваем train и test по группам на основе id\n",
    "train_data_grouped = train_data.groupby('group_id')\n",
    "test_data_grouped = test_data.groupby('group_id')"
   ],
   "metadata": {
    "id": "Se50llZN-wId",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:20:05.781466Z",
     "start_time": "2024-06-01T23:20:05.776170Z"
    }
   },
   "id": "Se50llZN-wId",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T23:20:06.538818Z",
     "start_time": "2024-06-01T23:20:06.537169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Функция для вычисления RMS\n",
    "# def fillna_with_rms(df):\n",
    "#     rms_values = np.sqrt(np.nanmean(df**2, axis=0))\n",
    "#     df_filled = df.copy()\n",
    "#     for idx, col in enumerate(df.columns):\n",
    "#         df_filled[col].fillna(rms_values[idx], inplace=True)\n",
    "#     return df_filled"
   ],
   "id": "e803b38d88379a27",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "# Фичи для трейна и теста\n",
    "train_similarity_features = calc_cosine_similarity(train_data_grouped)\n",
    "train_clustering_features = clustering_features(train_data_grouped)\n",
    "\n",
    "test_similarity_features = calc_cosine_similarity(test_data_grouped)\n",
    "test_clustering_features = clustering_features(test_data_grouped)\n",
    "\n",
    "# Замена пропусков на квадратично средние значения\n",
    "train_similarity_features = train_similarity_features(0)\n",
    "test_similarity_features = test_similarity_features(0)"
   ],
   "metadata": {
    "id": "dVLxFEej-05S",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:22:16.159492Z",
     "start_time": "2024-06-01T23:22:16.138959Z"
    }
   },
   "id": "dVLxFEej-05S",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Замена пропусков на квадратично средние значения\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m train_similarity_features \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_similarity_features\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m test_similarity_features \u001B[38;5;241m=\u001B[39m test_similarity_features(\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Объединяем новые признаки с исходным датасетом\n",
    "train_data = train_data.merge(train_similarity_features, on=['pair_id'])\n",
    "train_data = train_data.merge(train_clustering_features, on=['pair_id'])\n",
    "train_data = pd.concat([train_data, train_w2v_features, train_bert_features], axis=1)\n",
    "\n",
    "test_data = test_data.merge(test_similarity_features, on=['pair_id'])\n",
    "test_data = test_data.merge(test_clustering_features, on=['pair_id'])\n",
    "test_data = pd.concat([test_data, test_w2v_features, test_bert_features], axis=1)"
   ],
   "id": "9fd166546243b13f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Объединяем с BERT признаками\n",
    "train_data = pd.concat([train_data, train_w2v_features], axis=1)\n",
    "test_data = pd.concat([test_data, train_w2v_features], axis=1)"
   ],
   "metadata": {
    "id": "9rgzUnmCBuiV"
   },
   "id": "9rgzUnmCBuiV",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_data"
   ],
   "metadata": {
    "id": "G8ICGqhENLII"
   },
   "id": "G8ICGqhENLII",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "test_data"
   ],
   "metadata": {
    "id": "w-2ZEDA-NNgC"
   },
   "id": "w-2ZEDA-NNgC",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Разбиение на train, val и test"
   ],
   "metadata": {
    "id": "8E8QouA_PXMg"
   },
   "id": "8E8QouA_PXMg"
  },
  {
   "cell_type": "code",
   "source": [
    "# Определяем целевую переменную и признаки\n",
    "X_train = train_data.drop(columns=['doc_id', 'pair_id', 'group_id', 'target', 'title', 'title_processed', 'w2v_embeddings', 'bert_embeddings'])\n",
    "y_train = train_data['target']\n",
    "\n",
    "X_test = test_data.drop(columns=['doc_id', 'pair_id', 'group_id', 'title', 'title_processed', 'w2v_embeddings', 'bert_embeddings'])"
   ],
   "metadata": {
    "id": "gVKolUf9NQaB"
   },
   "id": "gVKolUf9NQaB",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "a44ddb55949afd80"
   },
   "cell_type": "code",
   "source": [
    "# Разбиваем данные на обучающие и валидационные\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_indices, val_indices = next(splitter.split(X_train, y_train, groups=train_data['group_id']))\n",
    "\n",
    "X_train_split = X_train.iloc[train_indices]\n",
    "y_train_split = y_train.iloc[train_indices]\n",
    "\n",
    "X_val_split = X_train.iloc[val_indices]\n",
    "y_val_split = y_train.iloc[val_indices]"
   ],
   "id": "a44ddb55949afd80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "7f184dcd67e56d89"
   },
   "cell_type": "code",
   "source": [
    "# Скейлинг данных\n",
    "scaler = StandardScaler()\n",
    "X_train_split = scaler.fit_transform(X_train_split)\n",
    "X_val_split = scaler.transform(X_val_split)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "7f184dcd67e56d89",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Обучение и инференс модели"
   ],
   "metadata": {
    "id": "zq6R8hgHPunk"
   },
   "id": "zq6R8hgHPunk"
  },
  {
   "metadata": {
    "id": "e73f61fe42d3bba8",
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "# Обучение модели CatBoost\n",
    "model = CatBoostClassifier()\n",
    "train_pool = Pool(X_train_split, y_train_split)\n",
    "val_pool = Pool(X_val_split, y_val_split)\n",
    "model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=100)"
   ],
   "id": "e73f61fe42d3bba8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "6b27cd263050e2c2"
   },
   "cell_type": "code",
   "source": [
    "# Предсказания на валидационной выборке\n",
    "val_predictions = model.predict(val_pool)"
   ],
   "id": "6b27cd263050e2c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "2ac4e01036617974",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f06602ad-93b8-46ae-ddef-5f8b744347ec"
   },
   "cell_type": "code",
   "source": [
    "# Оценка модели на валидации\n",
    "accuracy = accuracy_score(y_val_split, val_predictions)\n",
    "f1 = f1_score(y_val_split, val_predictions)\n",
    "report = classification_report(y_val_split, val_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(report)"
   ],
   "id": "2ac4e01036617974",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "e0caa42c21ec724d"
   },
   "cell_type": "code",
   "source": [
    "# Предсказание на тестовом наборе\n",
    "test_pool = Pool(X_test)\n",
    "test_predictions = model.predict(test_pool)"
   ],
   "id": "e0caa42c21ec724d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "initial_id",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "73c744bb-8091-4b12-d914-8c337add97eb"
   },
   "cell_type": "code",
   "source": [
    "# Сохранение результатов\n",
    "submission = test_groups[['pair_id']].copy()\n",
    "submission['target'] = test_predictions\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print('Файл с предсказаниями создан: submission.csv')"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "    ",
   "id": "5b5465361c487a8e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
