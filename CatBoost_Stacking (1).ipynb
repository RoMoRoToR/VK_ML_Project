{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#Загрузка моделей и библиотек"
   ],
   "metadata": {
    "id": "R8Igddv6CM66"
   },
   "id": "R8Igddv6CM66"
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install catboost\n",
    "!pip install pymorphy2\n",
    "!pip install patool"
   ],
   "metadata": {
    "collapsed": true,
    "id": "gW_g1cuiifMO",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1abc0206-383d-408d-cdbb-baf1ceb4aa56",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:31:12.671963Z",
     "start_time": "2024-06-01T23:31:08.853911Z"
    }
   },
   "id": "gW_g1cuiifMO",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in ./venv/lib/python3.9/site-packages (1.2.5)\r\n",
      "Requirement already satisfied: graphviz in ./venv/lib/python3.9/site-packages (from catboost) (0.20.3)\r\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.9/site-packages (from catboost) (3.9.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.0 in ./venv/lib/python3.9/site-packages (from catboost) (1.26.4)\r\n",
      "Requirement already satisfied: pandas>=0.24 in ./venv/lib/python3.9/site-packages (from catboost) (2.2.2)\r\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.9/site-packages (from catboost) (1.11.0)\r\n",
      "Requirement already satisfied: plotly in ./venv/lib/python3.9/site-packages (from catboost) (5.22.0)\r\n",
      "Requirement already satisfied: six in ./venv/lib/python3.9/site-packages (from catboost) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2024.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (4.52.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (24.0)\r\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (10.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (3.1.2)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (6.4.0)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./venv/lib/python3.9/site-packages (from plotly->catboost) (8.3.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.19.0)\r\n",
      "Requirement already satisfied: pymorphy2 in ./venv/lib/python3.9/site-packages (0.9.1)\r\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in ./venv/lib/python3.9/site-packages (from pymorphy2) (0.7.2)\r\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in ./venv/lib/python3.9/site-packages (from pymorphy2) (2.4.417127.4579844)\r\n",
      "Requirement already satisfied: docopt>=0.6 in ./venv/lib/python3.9/site-packages (from pymorphy2) (0.6.2)\r\n",
      "Requirement already satisfied: patool in ./venv/lib/python3.9/site-packages (1.15.0)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "901132e79c82f040",
   "metadata": {
    "collapsed": true,
    "id": "901132e79c82f040",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:31:15.663754Z",
     "start_time": "2024-06-01T23:31:12.673851Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pymorphy2\n",
    "import patoolib\n",
    "import os\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.cluster import DBSCAN\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, classification_report, accuracy_score\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Загрузка данных"
   ],
   "metadata": {
    "id": "mW6VWhQGCVfc"
   },
   "id": "mW6VWhQGCVfc"
  },
  {
   "metadata": {
    "id": "dcd259dbdd5e5cdd",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:31:15.720693Z",
     "start_time": "2024-06-01T23:31:15.664559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загрузка данных\n",
    "train_groups = pd.read_csv('train_groups.csv')\n",
    "test_groups = pd.read_csv('test_groups.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "docs_titles = pd.read_csv('docs_titles.tsv', sep='\\t')"
   ],
   "id": "dcd259dbdd5e5cdd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "id": "211e55804f9f14e9",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:31:15.728512Z",
     "start_time": "2024-06-01T23:31:15.721486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Объединение заголовков с данными групп\n",
    "train_data = train_groups.merge(docs_titles, on='doc_id')\n",
    "test_data = test_groups.merge(docs_titles, on='doc_id', how='left')"
   ],
   "id": "211e55804f9f14e9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# Просмотр пропусков\n",
    "train_data.isna().sum(), test_data.isna().sum()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "diC4wvt9rW3O",
    "outputId": "23749e25-b2fd-49fc-a474-52986923db29",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:31:15.736373Z",
     "start_time": "2024-06-01T23:31:15.730339Z"
    }
   },
   "id": "diC4wvt9rW3O",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pair_id      0\n",
       " group_id     0\n",
       " doc_id       0\n",
       " target       0\n",
       " title       16\n",
       " dtype: int64,\n",
       " pair_id      0\n",
       " group_id     0\n",
       " doc_id       0\n",
       " title       92\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "id": "c1a03e30037f5f40",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:31:15.741458Z",
     "start_time": "2024-06-01T23:31:15.737184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Обработка отсутствующих значений\n",
    "train_data['title'].fillna('', inplace=True)\n",
    "test_data['title'].fillna('', inplace=True)"
   ],
   "id": "c1a03e30037f5f40",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Предобработка данных"
   ],
   "metadata": {
    "id": "VNibqmm-CZHf"
   },
   "id": "VNibqmm-CZHf"
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "3d0f7e2e523b5231",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:31:16.519936Z",
     "start_time": "2024-06-01T23:31:15.742252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загрузка данных для NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Стоп-слова и шум\n",
    "stop_words = set(stopwords.words('russian')) | set(stopwords.words('english'))\n",
    "\n",
    "# Пробуем стеммер или леммер\n",
    "stemmer = SnowballStemmer(\"russian\")\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ],
   "id": "3d0f7e2e523b5231",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/taniyashuba/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/taniyashuba/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/taniyashuba/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "id": "b882508403a74291",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:31:33.851904Z",
     "start_time": "2024-06-01T23:31:16.521044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Токенизация + лемматизация/стемминг текста\n",
    "    \"\"\"\n",
    "    text = re.sub(r'<.*?>', '', text)  # Удаление HTML-тегов\n",
    "    text = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', text.lower())  # Удаление спецсимволов\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stop_words and not token.isdigit()]\n",
    "    # tokens = [stemmer.stem(word) for word in tokens]\n",
    "    tokens = [morph.parse(word)[0].normal_form for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "train_data['title_processed'] = train_data['title'].apply(preprocess_text)\n",
    "test_data['title_processed'] = test_data['title'].apply(preprocess_text)"
   ],
   "id": "b882508403a74291",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Векторизация BERT"
   ],
   "metadata": {
    "id": "DUPVkQXoCi6I"
   },
   "id": "DUPVkQXoCi6I"
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "dcdfe60cee23b604",
    "ExecuteTime": {
     "end_time": "2024-06-01T23:43:56.865395Z",
     "start_time": "2024-06-01T23:31:33.852775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Векторизация с помощью BERT\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze().cpu()\n",
    "\n",
    "train_data['title_embeddings'] = train_data['title'].apply(lambda x: get_bert_embeddings(x).numpy())\n",
    "test_data['title_embeddings'] = test_data['title'].apply(lambda x: get_bert_embeddings(x).numpy())"
   ],
   "id": "dcdfe60cee23b604",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 13\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\u001B[38;5;241m.\u001B[39mlast_hidden_state[:, \u001B[38;5;241m0\u001B[39m, :]\u001B[38;5;241m.\u001B[39msqueeze()\u001B[38;5;241m.\u001B[39mcpu()\n\u001B[1;32m     12\u001B[0m train_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtitle_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m train_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtitle\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: get_bert_embeddings(x)\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[0;32m---> 13\u001B[0m test_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtitle_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mtest_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtitle\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mget_bert_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/pandas/core/series.py:4917\u001B[0m, in \u001B[0;36mSeries.apply\u001B[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[0m\n\u001B[1;32m   4789\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[1;32m   4790\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4791\u001B[0m     func: AggFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4796\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4797\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m   4798\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4799\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[1;32m   4800\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4915\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[1;32m   4916\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4917\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4918\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4920\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4922\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4924\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/pandas/core/apply.py:1427\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_compat()\n\u001B[1;32m   1426\u001B[0m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[0;32m-> 1427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/pandas/core/apply.py:1507\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1501\u001B[0m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[1;32m   1504\u001B[0m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[1;32m   1505\u001B[0m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[1;32m   1506\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj\u001B[38;5;241m.\u001B[39mdtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1507\u001B[0m mapped \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1508\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[1;32m   1509\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[1;32m   1512\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[1;32m   1513\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[1;32m   1514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/pandas/core/base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[0;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[1;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[1;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[0;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/pandas/core/algorithms.py:1743\u001B[0m, in \u001B[0;36mmap_array\u001B[0;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[1;32m   1741\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1743\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[1;32m   1746\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[1;32m   1747\u001B[0m     )\n",
      "File \u001B[0;32mlib.pyx:2972\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "Cell \u001B[0;32mIn[9], line 13\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\u001B[38;5;241m.\u001B[39mlast_hidden_state[:, \u001B[38;5;241m0\u001B[39m, :]\u001B[38;5;241m.\u001B[39msqueeze()\u001B[38;5;241m.\u001B[39mcpu()\n\u001B[1;32m     12\u001B[0m train_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtitle_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m train_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtitle\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: get_bert_embeddings(x)\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[0;32m---> 13\u001B[0m test_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtitle_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m test_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtitle\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mget_bert_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mnumpy())\n",
      "Cell \u001B[0;32mIn[9], line 9\u001B[0m, in \u001B[0;36mget_bert_embeddings\u001B[0;34m(text)\u001B[0m\n\u001B[1;32m      7\u001B[0m inputs \u001B[38;5;241m=\u001B[39m tokenizer(text, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m512\u001B[39m, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m----> 9\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outputs\u001B[38;5;241m.\u001B[39mlast_hidden_state[:, \u001B[38;5;241m0\u001B[39m, :]\u001B[38;5;241m.\u001B[39msqueeze()\u001B[38;5;241m.\u001B[39mcpu()\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1137\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1130\u001B[0m \u001B[38;5;66;03m# Prepare head mask if needed\u001B[39;00m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m \u001B[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001B[39;00m\n\u001B[1;32m   1133\u001B[0m \u001B[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001B[39;00m\n\u001B[1;32m   1134\u001B[0m \u001B[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001B[39;00m\n\u001B[1;32m   1135\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[0;32m-> 1137\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1138\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1139\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1141\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1142\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1143\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1144\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1145\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1146\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1147\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1148\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1149\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1150\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:690\u001B[0m, in \u001B[0;36mBertEncoder.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    679\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m    680\u001B[0m         layer_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m    681\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    687\u001B[0m         output_attentions,\n\u001B[1;32m    688\u001B[0m     )\n\u001B[1;32m    689\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 690\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    692\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    693\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    694\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    695\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    696\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    697\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    698\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    700\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    701\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:580\u001B[0m, in \u001B[0;36mBertLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    570\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    577\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[1;32m    579\u001B[0m     self_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[:\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 580\u001B[0m     self_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    581\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    583\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    584\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    585\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    586\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    587\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m self_attention_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    589\u001B[0m     \u001B[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:519\u001B[0m, in \u001B[0;36mBertAttention.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[1;32m    500\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m    501\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    502\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    508\u001B[0m     output_attentions: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    509\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m    510\u001B[0m     self_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mself(\n\u001B[1;32m    511\u001B[0m         hidden_states,\n\u001B[1;32m    512\u001B[0m         attention_mask,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    517\u001B[0m         output_attentions,\n\u001B[1;32m    518\u001B[0m     )\n\u001B[0;32m--> 519\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[43m(\u001B[49m\u001B[43mself_outputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    520\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (attention_output,) \u001B[38;5;241m+\u001B[39m self_outputs[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n\u001B[1;32m    521\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:463\u001B[0m, in \u001B[0;36mBertSelfOutput.forward\u001B[0;34m(self, hidden_states, input_tensor)\u001B[0m\n\u001B[1;32m    461\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdense(hidden_states)\n\u001B[1;32m    462\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(hidden_states)\n\u001B[0;32m--> 463\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLayerNorm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    464\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m hidden_states\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/torch/nn/modules/normalization.py:201\u001B[0m, in \u001B[0;36mLayerNorm.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    200\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 201\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalized_shape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/torch/nn/functional.py:2573\u001B[0m, in \u001B[0;36mlayer_norm\u001B[0;34m(input, normalized_shape, weight, bias, eps)\u001B[0m\n\u001B[1;32m   2569\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_variadic(\u001B[38;5;28minput\u001B[39m, weight, bias):\n\u001B[1;32m   2570\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m   2571\u001B[0m         layer_norm, (\u001B[38;5;28minput\u001B[39m, weight, bias), \u001B[38;5;28minput\u001B[39m, normalized_shape, weight\u001B[38;5;241m=\u001B[39mweight, bias\u001B[38;5;241m=\u001B[39mbias, eps\u001B[38;5;241m=\u001B[39meps\n\u001B[1;32m   2572\u001B[0m     )\n\u001B[0;32m-> 2573\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mlayer_norm(\u001B[38;5;28minput\u001B[39m, normalized_shape, weight, bias, eps, \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackends\u001B[49m\u001B[38;5;241m.\u001B[39mcudnn\u001B[38;5;241m.\u001B[39menabled)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Создание фичей"
   ],
   "metadata": {
    "id": "u-eLsZEzCoJM"
   },
   "id": "u-eLsZEzCoJM"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BERT фичи"
   ],
   "metadata": {
    "id": "Xw1A-AuCvsMY"
   },
   "id": "Xw1A-AuCvsMY"
  },
  {
   "metadata": {
    "id": "e8c2bde5a6973eeb"
   },
   "cell_type": "code",
   "source": [
    "def embeddings_to_features(data, column_prefix):\n",
    "    \"\"\"\n",
    "    Преобразуем эмбеддинги в фичи\n",
    "    \"\"\"\n",
    "    embeddings = np.stack(data[column_prefix + '_embeddings'].values)\n",
    "    feature_names = [f\"{column_prefix}_embedding_{i}\" for i in range(embeddings.shape[1])]\n",
    "    features_df = pd.DataFrame(embeddings, columns=feature_names, index=data.index)\n",
    "    return features_df\n",
    "\n",
    "train_features = embeddings_to_features(train_data, 'title')\n",
    "test_features = embeddings_to_features(test_data, 'title')"
   ],
   "id": "e8c2bde5a6973eeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "36db76a1201238de"
   },
   "cell_type": "code",
   "source": [
    "def add_new_features(data):\n",
    "    \"\"\"\n",
    "    Добавляем новые признаки: длина заголовка и число уникальных слов\n",
    "    \"\"\"\n",
    "    data['title_length'] = data['title'].apply(lambda x: len(x.split()))\n",
    "    data['unique_words'] = data['title_processed'].apply(lambda x: len(set(x)))\n",
    "    return data\n",
    "\n",
    "train_data = add_new_features(train_data)\n",
    "test_data = add_new_features(test_data)"
   ],
   "id": "36db76a1201238de",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Косинусные сходства Tfidf"
   ],
   "metadata": {
    "id": "Iyiuf3Im5UgY"
   },
   "id": "Iyiuf3Im5UgY"
  },
  {
   "cell_type": "code",
   "source": [
    "def vectorize_group(group):\n",
    "    \"\"\"\n",
    "    Векторизуем группу документов с кастомным токенайзером\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(tokenizer=preprocess_text)\n",
    "    vectors = vectorizer.fit_transform(group['title'])\n",
    "    return vectors"
   ],
   "metadata": {
    "id": "gTq75O_sK58M"
   },
   "id": "gTq75O_sK58M",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def data_to_tfidf(data_grouped):\n",
    "    \"\"\"\n",
    "    Создание tfidf матрицы для данных по группам\n",
    "    \"\"\"\n",
    "    tfidf_data = pd.DataFrame()\n",
    "    for name, group in tqdm(data_grouped, desc=\"Processing groups\"):\n",
    "        # Для каждой группы получаем векторное представление\n",
    "        tfidf_matrix = vectorize_group(group)\n",
    "        tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=[f'tfidf_{i}' for i in range(tfidf_matrix.shape[1])], index=group.index)\n",
    "        # Соединяем в df все группы\n",
    "        tfidf_data = pd.concat([tfidf_data, tfidf_df])\n",
    "    return tfidf_data"
   ],
   "metadata": {
    "id": "vxNwYOBA5BlG"
   },
   "id": "vxNwYOBA5BlG",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def cosine_matrix_group(group):\n",
    "    \"\"\"\n",
    "    Вычисление матрицы косинусных расстояний для группы\n",
    "    \"\"\"\n",
    "    tfidf_matrix = vectorize_group(group)\n",
    "    cosine_matrix = cosine_similarity(tfidf_matrix)\n",
    "    return cosine_matrix"
   ],
   "metadata": {
    "id": "UQDLq8PQ5aqB"
   },
   "id": "UQDLq8PQ5aqB",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def calc_cosine_similarity(data_grouped, count=10):\n",
    "    \"\"\"\n",
    "    Возвращаем топ косинусных сходств для каждого документа группы\n",
    "    \"\"\"\n",
    "    similarity_features_list = []\n",
    "    for name, group in tqdm(data_grouped, desc=\"Processing groups\"):\n",
    "        cosine_matrix = cosine_matrix_group(group)\n",
    "        for k, (idx, row) in enumerate(group.iterrows()):\n",
    "            similarities = []\n",
    "            for j in range(len(group)):\n",
    "                if k == j:\n",
    "                    continue\n",
    "                similarities.append(cosine_matrix[k, j])\n",
    "            top_similarities = sorted(similarities, reverse=True)[:count]\n",
    "            similarity_record = [row['pair_id']] + top_similarities\n",
    "            similarity_features_list.append(similarity_record)\n",
    "    similarity_columns = ['pair_id'] + [f'top_{i+1}_similarity' for i in range(count)]\n",
    "    similarity_features = pd.DataFrame(similarity_features_list, columns=similarity_columns)\n",
    "    return similarity_features"
   ],
   "metadata": {
    "id": "Q5xUL97czxwE"
   },
   "id": "Q5xUL97czxwE",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Кластеризация"
   ],
   "metadata": {
    "id": "d6dDho3z5ZBz"
   },
   "id": "d6dDho3z5ZBz"
  },
  {
   "cell_type": "code",
   "source": [
    "def clustering_features(data_grouped, eps=0.5, min_samples=5, metric='cosine'):\n",
    "    \"\"\"\n",
    "    Возвращаем кластер для каждого документа группы\n",
    "    \"\"\"\n",
    "    clustering_features_list = []\n",
    "    for name, group in tqdm(data_grouped, desc=\"Processing groups\"):\n",
    "        cosine_matrix = cosine_matrix_group(group)\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples, metric=metric).fit(cosine_matrix)\n",
    "        cluster_labels = dbscan.labels_\n",
    "        for k, (idx, row) in enumerate(group.iterrows()):\n",
    "            clustering_record = [row['pair_id'], cluster_labels[k]]\n",
    "            clustering_features_list.append(clustering_record)\n",
    "    clustering_columns = ['pair_id', 'cluster']\n",
    "    clustering_features = pd.DataFrame(clustering_features_list, columns=clustering_columns)\n",
    "    return clustering_features"
   ],
   "metadata": {
    "id": "lCUlD0rm9S6t"
   },
   "id": "lCUlD0rm9S6t",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Работа с остальным текстом"
   ],
   "metadata": {
    "id": "smSWBFPaEr3i"
   },
   "id": "smSWBFPaEr3i"
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_bigtext(text):\n",
    "    \"\"\"\n",
    "    Токенизация + лемматизация/стемминг текста\n",
    "    \"\"\"\n",
    "    text = re.sub(r'<.*?>', '', text)  # Удаление HTML-тегов\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+|@\\S+', '', text)  # Удаление URL и email-адресов\n",
    "    text = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', text.lower())  # Удаление спецсимволов\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Удаление дополнительных пробелов\n",
    "\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stop_words and not token.isdigit() and len(token) > 1]\n",
    "    # tokens = [stemmer.stem(word) for word in tokens]\n",
    "    tokens = [morph.parse(word)[0].normal_form for word in tokens]\n",
    "    return tokens"
   ],
   "metadata": {
    "id": "x_rZqhBGPbFw"
   },
   "id": "x_rZqhBGPbFw",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "EKzf6XBsEvPk"
   },
   "id": "EKzf6XBsEvPk",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "zip_file_path = '/content/drive/My Drive/ML_Project/doc_to_text.zip'\n",
    "extract_dir = '/content/doc_to_text'\n",
    "\n",
    "if not os.path.exists(extract_dir):\n",
    "    os.makedirs(extract_dir)\n",
    "\n",
    "patoolib.extract_archive(zip_file_path, outdir=extract_dir)"
   ],
   "metadata": {
    "id": "Ppt4gEaRF3Jt"
   },
   "id": "Ppt4gEaRF3Jt",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "doc_to_text = pd.read_csv('/content/doc_to_text/doc_to_text.tsv', sep='\\t')"
   ],
   "metadata": {
    "id": "eo5KzA-sJcRK"
   },
   "id": "eo5KzA-sJcRK",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_texts = doc_to_text[doc_to_text['doc_id'].isin(train_groups['doc_id'])]\n",
    "train_texts = train_groups.merge(train_texts, on='doc_id')\n",
    "train_texts.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "u0L9ghPeLOs9",
    "outputId": "1bf08718-1d0b-409c-f30e-c711e756b46a"
   },
   "id": "u0L9ghPeLOs9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "tqdm.pandas(desc=\"Tokenizing texts\")\n",
    "train_texts['text_processed'] = train_texts['text'].progress_apply(preprocess_bigtext)"
   ],
   "metadata": {
    "id": "qvshH7LSOca7"
   },
   "id": "qvshH7LSOca7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def get_most_common_tokens(tokens, top_n=10):\n",
    "    counter = Counter(tokens)\n",
    "    most_common = counter.most_common(top_n)\n",
    "    return {token for token, freq in most_common}"
   ],
   "metadata": {
    "id": "h1lIIGppL_zP"
   },
   "id": "h1lIIGppL_zP",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Словарь для хранения токенов групп\n",
    "group_tokens = {}\n",
    "\n",
    "# Обработка каждой группы\n",
    "for group_id, group_data in tqdm(train_texts.groupby('group_id'), desc=\"Processing Groups\"):\n",
    "    all_tokens = []\n",
    "\n",
    "    # Сбор токенов всех документов группы\n",
    "    for text in group_data['text']:\n",
    "        tokens = preprocess_text(text)\n",
    "        all_tokens.extend(tokens)\n",
    "\n",
    "    # Получение самых частых токенов группы\n",
    "    group_tokens[group_id] = get_most_common_tokens(all_tokens, top_n=10)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "n0NGHTq0LzZA",
    "outputId": "60d07101-e375-40f3-c508-d784ed98b802"
   },
   "id": "n0NGHTq0LzZA",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "qCSob1iGKLzc"
   },
   "id": "qCSob1iGKLzc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Косинусные сходства BERT embeddings"
   ],
   "metadata": {
    "id": "gIXXaq0g5a70"
   },
   "id": "gIXXaq0g5a70"
  },
  {
   "cell_type": "code",
   "source": [
    "def emb_cosine_matrix_group(group):\n",
    "    \"\"\"\n",
    "    Вычисление матрицы косинусных расстояний для группы\n",
    "    \"\"\"\n",
    "    emb_matrix = np.vstack(group['title_embeddings'].values)\n",
    "    cosine_matrix = cosine_similarity(emb_matrix)\n",
    "    return cosine_matrix"
   ],
   "metadata": {
    "id": "LR-oUzSss6u7"
   },
   "id": "LR-oUzSss6u7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def emb_cosine_similarity(data_grouped, count=10):\n",
    "    \"\"\"\n",
    "    Возвращаем топ косинусных расстояний для группы по эмбеддингам\n",
    "    \"\"\"\n",
    "    similarity_features_list = []\n",
    "    for name, group in tqdm(data_grouped, desc=\"Processing groups\"):\n",
    "        cosine_matrix = emb_cosine_matrix_group(group)\n",
    "        for k, (idx, row) in enumerate(group.iterrows()):\n",
    "            similarities = []\n",
    "            for j in range(len(group)):\n",
    "                if k == j:\n",
    "                    continue\n",
    "                similarities.append(cosine_matrix[k, j])\n",
    "            top_similarities = sorted(similarities, reverse=True)[:count]\n",
    "            similarity_record = [row['pair_id']] + top_similarities\n",
    "            similarity_features_list.append(similarity_record)\n",
    "    similarity_columns = ['pair_id'] + [f'top_{i+1}_emb_similarity' for i in range(count)]\n",
    "    similarity_features = pd.DataFrame(similarity_features_list, columns=similarity_columns)\n",
    "    return similarity_features"
   ],
   "metadata": {
    "id": "6z_wJJz7r5J9"
   },
   "id": "6z_wJJz7r5J9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# WMD дистанции"
   ],
   "metadata": {
    "id": "JLHxqx7p5eQx"
   },
   "id": "JLHxqx7p5eQx"
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install POT"
   ],
   "metadata": {
    "id": "p_zo9e8LBIae"
   },
   "id": "p_zo9e8LBIae",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import gensim.downloader as api\n",
    "word2vec = api.load('word2vec-ruscorpora-300')"
   ],
   "metadata": {
    "id": "4HZVbYjx2X7i"
   },
   "id": "4HZVbYjx2X7i",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def remove_pos_tag(word):\n",
    "    return word.split('_')[0]\n",
    "\n",
    "key_to_index_no_pos = {remove_pos_tag(word): word for word in word2vec.key_to_index}\n",
    "\n",
    "\n",
    "def transform_text(text):\n",
    "    \"\"\"\n",
    "    Преобразует текст в список токенов, которые соответствуют форматам слов в модели\n",
    "    \"\"\"\n",
    "    transformed_text = [key_to_index_no_pos[word] for word in text if word in key_to_index_no_pos]\n",
    "    return transformed_text\n",
    "\n",
    "\n",
    "def wmd_features(data_grouped, model, count=10):\n",
    "    \"\"\"\n",
    "    Возвращаем топ WMD расстояний для группы\n",
    "    \"\"\"\n",
    "    distances_features_list = []\n",
    "    for name, group in tqdm(data_grouped, desc=\"Processing groups\"):\n",
    "        for k, (idx, row) in enumerate(group.iterrows()):\n",
    "            distances = []\n",
    "            transformed_k = transform_text(group['title_processed'].iloc[k])\n",
    "            for j in range(len(group)):\n",
    "                if k == j:\n",
    "                    continue\n",
    "                transformed_j = transform_text(group['title_processed'].iloc[j])\n",
    "                distances.append(model.wmdistance(transformed_k, transformed_j))\n",
    "            top_distances = sorted(distances)[:count]\n",
    "            distance_record = [row['pair_id']] + top_distances\n",
    "            distances_features_list.append(distance_record)\n",
    "    distance_columns = ['pair_id'] + [f'top_{i+1}_distances' for i in range(count)]\n",
    "    distance_features = pd.DataFrame(distances_features_list, columns=distance_columns)\n",
    "    return distance_features"
   ],
   "metadata": {
    "id": "lVzPvEQK_RSr"
   },
   "id": "lVzPvEQK_RSr",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "CRs7kakCEqmf"
   },
   "id": "CRs7kakCEqmf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Объединение данных и фичей в датасет"
   ],
   "metadata": {
    "id": "U-6p30UFC2P2"
   },
   "id": "U-6p30UFC2P2"
  },
  {
   "cell_type": "code",
   "source": [
    "# Разбиваем train и test по группам на основе id\n",
    "train_data_grouped = train_data.groupby('group_id')\n",
    "test_data_grouped = test_data.groupby('group_id')"
   ],
   "metadata": {
    "id": "Se50llZN-wId"
   },
   "id": "Se50llZN-wId",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Фичи для трейна и теста\n",
    "train_similarity_features = calc_cosine_similarity(train_data_grouped)\n",
    "train_clustering_features = clustering_features(train_data_grouped)\n",
    "# train_wmd_features = wmd_features(train_data_grouped, model=word2vec)\n",
    "# train_emb_similarity_features = emb_cosine_similarity(train_data_grouped)\n",
    "\n",
    "test_similarity_features = calc_cosine_similarity(test_data_grouped)\n",
    "test_clustering_features = clustering_features(test_data_grouped)\n",
    "# test_wmd_features = wmd_features(test_data_grouped, model=word2vec)\n",
    "# test_emb_similarity_features = emb_cosine_similarity(test_data_grouped)\n",
    "\n",
    "# Заполняем пропуски нулями\n",
    "train_similarity_features = train_similarity_features.fillna(0)\n",
    "# train_emb_similarity_features = train_emb_similarity_features.fillna(0)\n",
    "\n",
    "test_similarity_features = test_similarity_features.fillna(0)\n",
    "# test_emb_similarity_features = test_emb_similarity_features.fillna(0)\n",
    "\n",
    "\n",
    "# Объединяем новые признаки с исходным датасетом\n",
    "train_data = train_data.merge(train_similarity_features, on=['pair_id'])\n",
    "train_data = train_data.merge(train_clustering_features, on=['pair_id'])\n",
    "# train_data = train_data.merge(train_emb_similarity_features, on=['pair_id'])\n",
    "# train_data = train_data.merge(train_wmd_features, on=['pair_id'])\n",
    "\n",
    "test_data = test_data.merge(test_similarity_features, on=['pair_id'])\n",
    "test_data = test_data.merge(test_clustering_features, on=['pair_id'])\n",
    "# test_data = test_data.merge(test_emb_similarity_features, on=['pair_id'])\n",
    "# test_data = test_data.merge(test_wmd_features, on=['pair_id'])"
   ],
   "metadata": {
    "id": "dVLxFEej-05S"
   },
   "id": "dVLxFEej-05S",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Объединяем с BERT признаками\n",
    "train_data = pd.concat([train_data, train_features], axis=1)\n",
    "test_data = pd.concat([test_data, test_features], axis=1)"
   ],
   "metadata": {
    "id": "9rgzUnmCBuiV"
   },
   "id": "9rgzUnmCBuiV",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Разбиение на train, val и test"
   ],
   "metadata": {
    "id": "8E8QouA_PXMg"
   },
   "id": "8E8QouA_PXMg"
  },
  {
   "cell_type": "code",
   "source": [
    "X_train = train_data.drop(columns=['doc_id', 'pair_id', 'group_id', 'target', 'title', 'title_processed', 'title_embeddings'], axis=1)\n",
    "y_train = train_data['target']\n",
    "\n",
    "X_test = test_data.drop(columns=['doc_id', 'pair_id', 'group_id', 'title', 'title_processed', 'title_embeddings'], axis=1)"
   ],
   "metadata": {
    "id": "gVKolUf9NQaB"
   },
   "id": "gVKolUf9NQaB",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "a44ddb55949afd80"
   },
   "cell_type": "code",
   "source": [
    "# Разбиение данных на обучающую и валидационную выборки\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_indices, val_indices = next(splitter.split(X_train, y_train, train_groups['group_id']))\n",
    "\n",
    "X_train_split = X_train.iloc[train_indices]\n",
    "y_train_split = y_train.iloc[train_indices]\n",
    "\n",
    "X_val_split = X_train.iloc[val_indices]\n",
    "y_val_split = y_train.iloc[val_indices]"
   ],
   "id": "a44ddb55949afd80",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Обучение и валидация модели"
   ],
   "metadata": {
    "id": "zq6R8hgHPunk"
   },
   "id": "zq6R8hgHPunk"
  },
  {
   "metadata": {
    "id": "e73f61fe42d3bba8",
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "# Обучение модели CatBoost\n",
    "model = CatBoostClassifier()\n",
    "train_pool = Pool(X_train_split, y_train_split)\n",
    "val_pool = Pool(X_val_split, y_val_split)\n",
    "model.fit(train_pool, eval_set=val_pool)"
   ],
   "id": "e73f61fe42d3bba8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "6b27cd263050e2c2"
   },
   "cell_type": "code",
   "source": [
    "# Предсказания на валидационной выборке\n",
    "val_predictions = model.predict(val_pool)"
   ],
   "id": "6b27cd263050e2c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "2ac4e01036617974",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b72522e3-9938-4b0c-856d-1b4373a614c3"
   },
   "cell_type": "code",
   "source": [
    "# Оценка модели на валидации\n",
    "accuracy = accuracy_score(y_val_split, val_predictions)\n",
    "f1 = f1_score(y_val_split, val_predictions)\n",
    "report = classification_report(y_val_split, val_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(report)"
   ],
   "id": "2ac4e01036617974",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "best_params = model.get_all_params()\n",
    "valid_keys = [\n",
    "    'iterations', 'learning_rate', 'depth', 'l2_leaf_reg', 'model_size_reg',\n",
    "    'border_count', 'feature_border_type', 'ctr_description', 'ctr_border_count',\n",
    "    'ctr_leaf_count_limit', 'store_all_simple_ctr', 'max_ctr_complexity', 'priors',\n",
    "    'has_time', 'simple_ctr', 'combinations_ctr', 'per_feature_ctr', 'task_type',\n",
    "    'devices', 'bootstrap_type', 'subsample', 'sampling_unit', 'sampling_frequency',\n",
    "    'bootstrap_type', 'bagging_temperature', 'random_seed'\n",
    "]\n",
    "valid_params = {k: v for k, v in best_params.items() if k in valid_keys}\n",
    "valid_params['iterations'] = 350"
   ],
   "metadata": {
    "id": "igRwdSEnrbUo"
   },
   "id": "igRwdSEnrbUo",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "final_model = CatBoostClassifier(**valid_params)\n",
    "train_pool = Pool(X_train, y_train)\n",
    "final_model.fit(train_pool)"
   ],
   "metadata": {
    "id": "-M8yHVFkn-yZ"
   },
   "id": "-M8yHVFkn-yZ",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Стекинг"
   ],
   "metadata": {
    "id": "XfpoBThCcjZK"
   },
   "id": "XfpoBThCcjZK"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "class DjStacking(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Стэкинг моделей scikit-learn\"\"\"\n",
    "\n",
    "    def __init__(self, models, ens_model):\n",
    "        \"\"\"\n",
    "        Инициализация\n",
    "        models - базовые модели для стекинга\n",
    "        ens_model - мета-модель\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.ens_model = ens_model\n",
    "        self.n = len(models)\n",
    "        self.valid = None\n",
    "\n",
    "    def fit(self, groups_ids, X, y, p=0.25, cv=3, err=0.001, random_state=None):\n",
    "        \"\"\"\n",
    "        Обучение стекинга\n",
    "        p - в каком отношении делить на обучение / тест\n",
    "            если p = 0 - используем всё обучение!\n",
    "        cv  (при p=0) - сколько фолдов использовать\n",
    "        err (при p=0) - величина случайной добавки к метапризнакам\n",
    "        random_state - инициализация генератора\n",
    "\n",
    "        \"\"\"\n",
    "        if (p > 0): # делим на обучение и тест\n",
    "            # разбиение на обучение моделей и метамодели\n",
    "            # train, valid, y_train, y_valid = train_test_split(X, y, test_size=p, random_state=random_state)\n",
    "            splitter = GroupShuffleSplit(n_splits=1, test_size=p, random_state=random_state)\n",
    "            train_indices, val_indices = next(splitter.split(X, y, groups=groups_ids))\n",
    "            train = X.iloc[train_indices]\n",
    "            y_train = y.iloc[train_indices]\n",
    "            valid = X.iloc[val_indices]\n",
    "            y_valid = y.iloc[val_indices]\n",
    "\n",
    "\n",
    "            # заполнение матрицы для обучения метамодели\n",
    "            self.valid = np.zeros((valid.shape[0], self.n))\n",
    "            for t, clf in enumerate(self.models):\n",
    "                clf.fit(train, y_train)\n",
    "                self.valid[:, t] = clf.predict_proba(valid)[:, 1]\n",
    "\n",
    "            # обучение метамодели\n",
    "            self.ens_model.fit(X=self.valid, y=y_valid)\n",
    "\n",
    "        else: # используем всё обучение\n",
    "\n",
    "            # для регуляризации - берём случайные добавки\n",
    "            self.valid = err*np.random.randn(X.shape[0], self.n)\n",
    "\n",
    "            for t, clf in enumerate(self.models):\n",
    "                # это oob-ответы алгоритмов\n",
    "                self.valid[:, t] += cross_val_predict(clf, X, y, cv=cv, n_jobs=-1, method='predict_proba')[:, 1]\n",
    "                # но сам алгоритм надо настроить\n",
    "                clf.fit(X, y)\n",
    "\n",
    "            # обучение метамодели\n",
    "            self.ens_model.fit(self.valid, y)\n",
    "\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Работа стэкинга\n",
    "        \"\"\"\n",
    "        # заполение матрицы для мета-классификатора\n",
    "        X_meta = np.zeros((X.shape[0], self.n))\n",
    "\n",
    "        for t, clf in enumerate(self.models):\n",
    "            X_meta[:, t] = clf.predict(X)\n",
    "\n",
    "        a = self.ens_model.predict(X_meta)\n",
    "\n",
    "        return (a)"
   ],
   "metadata": {
    "id": "ujGhpCXcck1j"
   },
   "id": "ujGhpCXcck1j",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Базовые алгоритмы"
   ],
   "metadata": {
    "id": "hhwuuBeEcvE_"
   },
   "id": "hhwuuBeEcvE_"
  },
  {
   "cell_type": "code",
   "source": [
    "# Скейлинг данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "metadata": {
    "id": "MuwUES7rwXt1"
   },
   "id": "MuwUES7rwXt1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "# svm1 = OneClassSVM()\n",
    "# svm1.fit(X_train_scaled, y_train)\n",
    "\n",
    "# svc1 = SVC(probability=True)\n",
    "\n",
    "rf1 = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "cat1 = CatBoostClassifier(**valid_params)\n",
    "\n",
    "# cat2 = model"
   ],
   "metadata": {
    "id": "0kjDg1HAcw0Y"
   },
   "id": "0kjDg1HAcw0Y",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "svc1 = SVC(probability=True)\n",
    "svc1.fit(X_train, y_train)"
   ],
   "metadata": {
    "id": "ymbKli2Y7_pt"
   },
   "id": "ymbKli2Y7_pt",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "models = [knn1, knn2, rf1, rf2, cat1]\n",
    "ens_model = LogisticRegression()\n",
    "groups_ids = train_groups['group_id']\n",
    "s1 = DjStacking(models, ens_model)\n",
    "s1.fit(groups_ids, X_train, y_train)"
   ],
   "metadata": {
    "id": "ONz2TKiXdSDq"
   },
   "id": "ONz2TKiXdSDq",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "preds = s1.predict(X_test)"
   ],
   "metadata": {
    "id": "aJZIqSpSBXS5"
   },
   "id": "aJZIqSpSBXS5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Сохранение результатов\n",
    "submission = test_groups[['pair_id']].copy()\n",
    "submission['target'] = preds\n",
    "submission.to_csv('/content/submission.csv', index=False)\n",
    "\n",
    "print('Файл с предсказаниями создан: submission.csv')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q7VCIa8GB6BH",
    "outputId": "92db991f-8e46-4978-a3df-b5938315b85e"
   },
   "id": "q7VCIa8GB6BH",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Важность признаков"
   ],
   "metadata": {
    "id": "uPCmyRYV0B3m"
   },
   "id": "uPCmyRYV0B3m"
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = model.get_feature_importance(type='PredictionValuesChange')\n",
    "feature_importances = pd.Series(importances, index=X_train.columns).sort_values()[-15:]\n",
    "feature_importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importances.index, feature_importances.values)\n",
    "plt.title('CatBoost Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "ZX7l2sq3yxw3",
    "outputId": "3e9f203e-c78b-4eb5-bbb7-8c9b02e6d328"
   },
   "id": "ZX7l2sq3yxw3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Инференс"
   ],
   "metadata": {
    "id": "DjvL6p6alMp-"
   },
   "id": "DjvL6p6alMp-"
  },
  {
   "cell_type": "code",
   "source": [
    "test_pool = Pool(X_test)"
   ],
   "metadata": {
    "id": "HMPLJ120vDRU"
   },
   "id": "HMPLJ120vDRU",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "e0caa42c21ec724d"
   },
   "cell_type": "code",
   "source": [
    "# Предсказание на тестовом наборе\n",
    "test_predictions = model.predict(test_pool)"
   ],
   "id": "e0caa42c21ec724d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "initial_id",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4d7df4c6-d382-408e-d838-11cabfb89b6c"
   },
   "cell_type": "code",
   "source": [
    "# Сохранение результатов\n",
    "submission = test_groups[['pair_id']].copy()\n",
    "submission['target'] = test_predictions\n",
    "submission.to_csv('/content/submission.csv', index=False)\n",
    "\n",
    "print('Файл с предсказаниями создан: submission.csv')"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "test_final_predictions = final_model.predict(test_pool)"
   ],
   "metadata": {
    "id": "BQw6gvz2u5OU"
   },
   "id": "BQw6gvz2u5OU",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "submission = test_groups[['pair_id']].copy()\n",
    "submission['target'] = test_final_predictions\n",
    "submission.to_csv('/content/submission.csv', index=False)\n",
    "\n",
    "print('Файл с предсказаниями создан: submission.csv')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vipl06YIvAgQ",
    "outputId": "dfafa277-33fa-4439-b0b2-916bdd525126"
   },
   "id": "vipl06YIvAgQ",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
