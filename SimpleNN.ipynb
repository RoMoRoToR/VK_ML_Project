{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T09:29:54.460424Z",
     "start_time": "2024-05-29T09:29:50.340530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install catboost\n",
    "!pip install pymorphy2\n",
    "!pip install transformers"
   ],
   "id": "3cd5dad2a78c2eb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in ./venv/lib/python3.9/site-packages (1.2.5)\r\n",
      "Requirement already satisfied: graphviz in ./venv/lib/python3.9/site-packages (from catboost) (0.20.3)\r\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.9/site-packages (from catboost) (3.9.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.0 in ./venv/lib/python3.9/site-packages (from catboost) (1.26.4)\r\n",
      "Requirement already satisfied: pandas>=0.24 in ./venv/lib/python3.9/site-packages (from catboost) (2.2.2)\r\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.9/site-packages (from catboost) (1.13.1)\r\n",
      "Requirement already satisfied: plotly in ./venv/lib/python3.9/site-packages (from catboost) (5.22.0)\r\n",
      "Requirement already satisfied: six in ./venv/lib/python3.9/site-packages (from catboost) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2024.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (4.52.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (24.0)\r\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (10.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (3.1.2)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (6.4.0)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./venv/lib/python3.9/site-packages (from plotly->catboost) (8.3.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.19.0)\r\n",
      "Requirement already satisfied: pymorphy2 in ./venv/lib/python3.9/site-packages (0.9.1)\r\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in ./venv/lib/python3.9/site-packages (from pymorphy2) (0.7.2)\r\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in ./venv/lib/python3.9/site-packages (from pymorphy2) (2.4.417127.4579844)\r\n",
      "Requirement already satisfied: docopt>=0.6 in ./venv/lib/python3.9/site-packages (from pymorphy2) (0.6.2)\r\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.9/site-packages (4.41.1)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from transformers) (3.14.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in ./venv/lib/python3.9/site-packages (from transformers) (0.23.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.9/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.9/site-packages (from transformers) (24.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.9/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.9/site-packages (from transformers) (2024.5.15)\r\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (from transformers) (2.32.2)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./venv/lib/python3.9/site-packages (from transformers) (0.19.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv/lib/python3.9/site-packages (from transformers) (0.4.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.9/site-packages (from transformers) (4.66.4)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests->transformers) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests->transformers) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests->transformers) (2024.2.2)\r\n"
     ]
    }
   ],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T09:29:55.409727Z",
     "start_time": "2024-05-29T09:29:55.406058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pymorphy2\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.cluster import DBSCAN\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, classification_report, accuracy_score\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "id": "a221a78fea82e460",
   "outputs": [],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T09:29:55.985480Z",
     "start_time": "2024-05-29T09:29:55.933032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загрузка данных\n",
    "train_groups = pd.read_csv('train_groups.csv')\n",
    "test_groups = pd.read_csv('test_groups.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "docs_titles = pd.read_csv('docs_titles.tsv', sep='\\t')"
   ],
   "id": "34201a575ae573c8",
   "outputs": [],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T09:47:28.987184Z",
     "start_time": "2024-05-29T09:47:28.973163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Обработка отсутствующих значений\n",
    "train_data = train_groups.merge(docs_titles, on='doc_id')\n",
    "test_data = test_groups.merge(docs_titles, on='doc_id', how='left')\n",
    "train_data['title'].fillna('', inplace=True)\n",
    "test_data['title'].fillna('', inplace=True)"
   ],
   "id": "4a8a3f5eb57de0ed",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/d35_l8056xbbpvj6g4knhvsm0000gn/T/ipykernel_70093/2141710370.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data['title'].fillna('', inplace=True)\n",
      "/var/folders/87/d35_l8056xbbpvj6g4knhvsm0000gn/T/ipykernel_70093/2141710370.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data['title'].fillna('', inplace=True)\n"
     ]
    }
   ],
   "execution_count": 183
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T09:47:47.286926Z",
     "start_time": "2024-05-29T09:47:29.762298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загрузка данных для NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('russian')) | set(stopwords.words('english'))\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', text.lower())\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stop_words and not token.isdigit()]\n",
    "    tokens = [morph.parse(word)[0].normal_form for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "train_data['title_processed'] = train_data['title'].apply(preprocess_text)\n",
    "test_data['title_processed'] = test_data['title'].apply(preprocess_text)"
   ],
   "id": "a7776c3bbdbb9d58",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/taniyashuba/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/taniyashuba/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 184
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T10:22:58.904484Z",
     "start_time": "2024-05-29T10:12:57.131584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Векторизация с помощью BERT\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "def batch_get_bert_embeddings(texts, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        embeddings.extend(batch_embeddings)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "train_texts = train_data['title_processed'].tolist()\n",
    "test_texts = test_data['title_processed'].tolist()\n",
    "\n",
    "train_embeddings = batch_get_bert_embeddings(train_texts)\n",
    "test_embeddings = batch_get_bert_embeddings(test_texts)\n",
    "\n",
    "train_data['title_embeddings'] = list(train_embeddings)\n",
    "test_data['title_embeddings'] = list(test_embeddings)\n",
    "\n",
    "# Преобразование эмбеддингов в фичи\n",
    "def embeddings_to_features(data, column_prefix):\n",
    "    embeddings = np.array(data[column_prefix + '_embeddings'].tolist())  # Используем .tolist() для правильного преобразования\n",
    "    feature_names = [f\"{column_prefix}_embedding_{i}\" for i in range(embeddings.shape[1])]\n",
    "    features_df = pd.DataFrame(embeddings, columns=feature_names, index=data.index)\n",
    "    return features_df\n",
    "\n",
    "train_features = embeddings_to_features(train_data, 'title')\n",
    "test_features = embeddings_to_features(test_data, 'title')"
   ],
   "id": "1e154b2e7c4752aa",
   "outputs": [],
   "execution_count": 201
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T10:06:33.534969Z",
     "start_time": "2024-05-29T10:06:33.419682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Новые признаки\n",
    "def add_new_features(data):\n",
    "    data['title_length'] = data['title'].apply(lambda x: len(x.split()))\n",
    "    data['unique_words'] = data['title_processed'].apply(lambda x: len(set(x.split())))\n",
    "    return data\n",
    "\n",
    "train_data = add_new_features(train_data)\n",
    "test_data = add_new_features(test_data)\n",
    "\n",
    "enhanced_train_data = pd.concat([train_data, train_features], axis=1)\n",
    "enhanced_test_data = pd.concat([test_data, test_features], axis=1)"
   ],
   "id": "d975b82c71299ad8",
   "outputs": [],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T10:06:43.842832Z",
     "start_time": "2024-05-29T10:06:43.170881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Подготовка данных для обучения\n",
    "X_train = enhanced_train_data.drop(columns=['doc_id', 'pair_id', 'group_id', 'target', 'title', 'title_processed'], axis=1).values\n",
    "y_train = enhanced_train_data['target'].values\n",
    "X_test = enhanced_test_data.drop(columns=['doc_id', 'pair_id', 'group_id', 'title', 'title_processed'], axis=1).values\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_indices, val_indices = next(splitter.split(X_train, y_train, groups=train_groups['group_id']))\n",
    "\n",
    "X_train_split = X_train[train_indices]\n",
    "y_train_split = y_train[train_indices]\n",
    "\n",
    "X_val_split = X_train[val_indices]\n",
    "y_val_split = y_train[val_indices]"
   ],
   "id": "f7b2b9e44ab3ffaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 196,
   "source": [
    "# Убедитесь, что все данные в виде 2D массивов и преобразованы в float\n",
    "X_train_split = np.vstack([np.array(x).astype(np.float32) for x in X_train_split])\n",
    "X_val_split = np.vstack([np.array(x).astype(np.float32) for x in X_val_split])\n",
    "X_test = np.vstack([np.array(x).astype(np.float32) for x in X_test])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_split)\n",
    "X_val_scaled = scaler.transform(X_val_split)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "id": "7b726db18566713c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T10:12:17.262253Z",
     "start_time": "2024-05-29T10:12:17.256467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, features, labels=None):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long) if labels is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is not None:\n",
    "            return self.features[idx], self.labels[idx]\n",
    "        return self.features[idx]\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        return out"
   ],
   "id": "6a82a3444c397ed",
   "outputs": [],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T10:12:23.437372Z",
     "start_time": "2024-05-29T10:12:23.434535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameters\n",
    "input_size = X_train_scaled.shape[1]\n",
    "num_classes = 2  # Assuming binary classification\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "batch_size = 32"
   ],
   "id": "1728bc1cb0f06721",
   "outputs": [],
   "execution_count": 199
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T10:12:23.960991Z",
     "start_time": "2024-05-29T10:12:23.946625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare datasets and dataloaders\n",
    "train_dataset = TextDataset(X_train_scaled, y_train_split.values)\n",
    "val_dataset = TextDataset(X_val_scaled, y_val_split.values)\n",
    "test_dataset = TextDataset(X_test_scaled)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "870a5d2a04ca3ea4",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[200], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Prepare datasets and dataloaders\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m TextDataset(X_train_scaled, \u001B[43my_train_split\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m)\n\u001B[1;32m      3\u001B[0m val_dataset \u001B[38;5;241m=\u001B[39m TextDataset(X_val_scaled, y_val_split\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m      4\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m TextDataset(X_test_scaled)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "execution_count": 200
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Model, criterion, and optimizer\n",
    "model = SimpleNN(input_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "id": "f43417e91e99d0d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for features, labels in train_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ],
   "id": "f50ed0d3d5993d3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Validation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_predictions.extend(predicted.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_f1 = f1_score(val_labels, val_predictions, average='weighted')\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Validation F1-score: {val_f1:.4f}\")"
   ],
   "id": "caeb9d409269372"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Test predictions\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "with torch.no_grad():\n",
    "    for features in test_loader:\n",
    "        features = features.to(device)\n",
    "        outputs = model(features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_predictions.extend(predicted.cpu().numpy())"
   ],
   "id": "7c215cd831c73969"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Saving predictions\n",
    "submission = test_groups[['pair_id']].copy()\n",
    "submission['target'] = test_predictions\n",
    "submission.to_csv('/content/submission.csv', index=False)\n",
    "\n",
    "print('Файл с предсказаниями создан: submission.csv')"
   ],
   "id": "98b3776e396f945e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "84447d1fc4cdece5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "6f66c708db4391e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in ./venv/lib/python3.9/site-packages (1.2.5)\r\n",
      "Requirement already satisfied: graphviz in ./venv/lib/python3.9/site-packages (from catboost) (0.20.3)\r\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.9/site-packages (from catboost) (3.9.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.0 in ./venv/lib/python3.9/site-packages (from catboost) (1.26.4)\r\n",
      "Requirement already satisfied: pandas>=0.24 in ./venv/lib/python3.9/site-packages (from catboost) (2.2.2)\r\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.9/site-packages (from catboost) (1.13.1)\r\n",
      "Requirement already satisfied: plotly in ./venv/lib/python3.9/site-packages (from catboost) (5.22.0)\r\n",
      "Requirement already satisfied: six in ./venv/lib/python3.9/site-packages (from catboost) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2024.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (4.52.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (24.0)\r\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (10.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (3.1.2)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./venv/lib/python3.9/site-packages (from matplotlib->catboost) (6.4.0)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./venv/lib/python3.9/site-packages (from plotly->catboost) (8.3.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.19.0)\r\n",
      "Requirement already satisfied: pymorphy2 in ./venv/lib/python3.9/site-packages (0.9.1)\r\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in ./venv/lib/python3.9/site-packages (from pymorphy2) (0.7.2)\r\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in ./venv/lib/python3.9/site-packages (from pymorphy2) (2.4.417127.4579844)\r\n",
      "Requirement already satisfied: docopt>=0.6 in ./venv/lib/python3.9/site-packages (from pymorphy2) (0.6.2)\r\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.9/site-packages (4.41.1)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from transformers) (3.14.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in ./venv/lib/python3.9/site-packages (from transformers) (0.23.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.9/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.9/site-packages (from transformers) (24.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.9/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.9/site-packages (from transformers) (2024.5.15)\r\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (from transformers) (2.32.2)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./venv/lib/python3.9/site-packages (from transformers) (0.19.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv/lib/python3.9/site-packages (from transformers) (0.4.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.9/site-packages (from transformers) (4.66.4)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests->transformers) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests->transformers) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests->transformers) (2024.2.2)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/d35_l8056xbbpvj6g4knhvsm0000gn/T/ipykernel_70093/1966752516.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data['title'].fillna('', inplace=True)\n",
      "/var/folders/87/d35_l8056xbbpvj6g4knhvsm0000gn/T/ipykernel_70093/1966752516.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data['title'].fillna('', inplace=True)\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/taniyashuba/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/taniyashuba/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/taniyashuba/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Processing groups:   0%|          | 0/129 [00:00<?, ?it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:   1%|          | 1/129 [00:00<00:13,  9.71it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:   2%|▏         | 3/129 [00:00<00:11, 10.74it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:   4%|▍         | 5/129 [00:00<00:13,  9.05it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:   5%|▌         | 7/129 [00:00<00:11, 11.00it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:   8%|▊         | 10/129 [00:00<00:09, 12.93it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:   9%|▉         | 12/129 [00:00<00:08, 13.46it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  11%|█         | 14/129 [00:01<00:07, 14.64it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  12%|█▏        | 16/129 [00:01<00:07, 14.57it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  14%|█▍        | 18/129 [00:01<00:08, 13.85it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  16%|█▌        | 20/129 [00:01<00:07, 13.95it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  17%|█▋        | 22/129 [00:01<00:07, 14.10it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  19%|█▊        | 24/129 [00:01<00:07, 14.13it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  20%|██        | 26/129 [00:01<00:07, 14.56it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  22%|██▏       | 28/129 [00:02<00:07, 13.17it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  23%|██▎       | 30/129 [00:02<00:07, 12.66it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  25%|██▍       | 32/129 [00:02<00:07, 12.27it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  26%|██▋       | 34/129 [00:02<00:07, 11.98it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  28%|██▊       | 36/129 [00:02<00:07, 11.77it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  29%|██▉       | 38/129 [00:02<00:07, 12.82it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  31%|███       | 40/129 [00:03<00:06, 13.20it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  33%|███▎      | 42/129 [00:03<00:06, 13.27it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  34%|███▍      | 44/129 [00:03<00:06, 12.86it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  36%|███▌      | 46/129 [00:03<00:06, 13.10it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  37%|███▋      | 48/129 [00:03<00:06, 12.47it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  39%|███▉      | 50/129 [00:03<00:06, 12.24it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  40%|████      | 52/129 [00:04<00:07, 10.91it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  42%|████▏     | 54/129 [00:04<00:06, 12.26it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  43%|████▎     | 56/129 [00:04<00:06, 12.04it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  45%|████▍     | 58/129 [00:04<00:06, 11.43it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  47%|████▋     | 60/129 [00:04<00:05, 11.56it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  48%|████▊     | 62/129 [00:04<00:05, 12.30it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  50%|████▉     | 64/129 [00:05<00:05, 11.52it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  51%|█████     | 66/129 [00:05<00:05, 11.54it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  53%|█████▎    | 68/129 [00:05<00:05, 11.82it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  54%|█████▍    | 70/129 [00:05<00:04, 12.69it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  56%|█████▌    | 72/129 [00:05<00:04, 12.78it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  57%|█████▋    | 74/129 [00:05<00:04, 12.67it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  59%|█████▉    | 76/129 [00:06<00:04, 12.97it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  60%|██████    | 78/129 [00:06<00:03, 12.79it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  62%|██████▏   | 80/129 [00:06<00:03, 13.34it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  64%|██████▎   | 82/129 [00:06<00:03, 13.37it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  65%|██████▌   | 84/129 [00:06<00:03, 13.86it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  67%|██████▋   | 86/129 [00:06<00:03, 11.89it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  69%|██████▉   | 89/129 [00:07<00:02, 13.76it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  71%|███████   | 91/129 [00:07<00:02, 13.70it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  72%|███████▏  | 93/129 [00:07<00:02, 12.54it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  74%|███████▎  | 95/129 [00:07<00:02, 12.05it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  75%|███████▌  | 97/129 [00:07<00:02, 11.38it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  77%|███████▋  | 99/129 [00:07<00:02, 10.93it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  78%|███████▊  | 101/129 [00:08<00:02, 11.07it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  80%|███████▉  | 103/129 [00:08<00:02, 10.11it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  81%|████████▏ | 105/129 [00:08<00:02, 10.24it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  83%|████████▎ | 107/129 [00:08<00:02, 10.64it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  84%|████████▍ | 109/129 [00:08<00:01, 10.28it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  86%|████████▌ | 111/129 [00:09<00:01,  9.83it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  87%|████████▋ | 112/129 [00:09<00:01,  9.71it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  88%|████████▊ | 114/129 [00:09<00:01, 10.51it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  90%|████████▉ | 116/129 [00:09<00:01, 11.81it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  91%|█████████▏| 118/129 [00:09<00:00, 11.78it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  93%|█████████▎| 120/129 [00:09<00:00, 12.72it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  95%|█████████▍| 122/129 [00:10<00:00, 12.25it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  96%|█████████▌| 124/129 [00:10<00:00, 12.23it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  98%|█████████▊| 126/129 [00:10<00:00, 11.84it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  99%|█████████▉| 128/129 [00:10<00:00, 12.19it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups: 100%|██████████| 129/129 [00:10<00:00, 12.17it/s]\n",
      "Processing groups:   0%|          | 0/180 [00:00<?, ?it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:   1%|          | 2/180 [00:00<00:16, 11.03it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:   2%|▏         | 4/180 [00:00<00:16, 10.66it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:   3%|▎         | 6/180 [00:00<00:14, 11.68it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:   4%|▍         | 8/180 [00:00<00:17,  9.61it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:   6%|▌         | 10/180 [00:00<00:15, 10.67it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:   7%|▋         | 12/180 [00:01<00:17,  9.66it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:   8%|▊         | 14/180 [00:01<00:15, 10.61it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:   9%|▉         | 16/180 [00:01<00:15, 10.80it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  11%|█         | 19/180 [00:01<00:12, 13.30it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  12%|█▏        | 21/180 [00:01<00:11, 13.70it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  13%|█▎        | 23/180 [00:01<00:11, 13.11it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  14%|█▍        | 25/180 [00:02<00:11, 13.22it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  15%|█▌        | 27/180 [00:02<00:13, 11.35it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  16%|█▌        | 29/180 [00:02<00:13, 11.40it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  17%|█▋        | 31/180 [00:02<00:12, 12.32it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  18%|█▊        | 33/180 [00:02<00:11, 12.81it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  19%|█▉        | 35/180 [00:03<00:13, 10.54it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  21%|██        | 37/180 [00:03<00:12, 11.00it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  22%|██▏       | 39/180 [00:03<00:12, 11.51it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  23%|██▎       | 41/180 [00:03<00:12, 11.24it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  24%|██▍       | 43/180 [00:03<00:11, 11.58it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  25%|██▌       | 45/180 [00:03<00:11, 11.44it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  26%|██▌       | 47/180 [00:04<00:12, 10.52it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  27%|██▋       | 49/180 [00:04<00:12, 10.53it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  28%|██▊       | 51/180 [00:04<00:11, 11.47it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  29%|██▉       | 53/180 [00:04<00:10, 11.75it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  31%|███       | 55/180 [00:04<00:09, 12.95it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  32%|███▏      | 57/180 [00:04<00:09, 12.32it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  33%|███▎      | 59/180 [00:05<00:11, 10.29it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  34%|███▍      | 61/180 [00:05<00:10, 11.30it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  35%|███▌      | 63/180 [00:05<00:10, 11.31it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  36%|███▌      | 65/180 [00:05<00:10, 10.88it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  37%|███▋      | 67/180 [00:05<00:10, 11.14it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  38%|███▊      | 69/180 [00:06<00:09, 11.81it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  39%|███▉      | 71/180 [00:06<00:09, 11.53it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  41%|████      | 73/180 [00:06<00:09, 11.36it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  42%|████▏     | 75/180 [00:06<00:09, 10.96it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  43%|████▎     | 77/180 [00:06<00:08, 11.79it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  44%|████▍     | 79/180 [00:06<00:08, 11.85it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  45%|████▌     | 81/180 [00:07<00:08, 11.72it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  46%|████▌     | 83/180 [00:07<00:07, 12.31it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  47%|████▋     | 85/180 [00:07<00:08, 11.71it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  48%|████▊     | 87/180 [00:07<00:08, 10.81it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  49%|████▉     | 89/180 [00:07<00:08, 11.21it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  51%|█████     | 91/180 [00:07<00:07, 11.91it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  52%|█████▏    | 93/180 [00:08<00:07, 11.56it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  53%|█████▎    | 95/180 [00:08<00:07, 11.49it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  54%|█████▍    | 97/180 [00:08<00:06, 12.85it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  55%|█████▌    | 99/180 [00:08<00:06, 13.14it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  56%|█████▌    | 101/180 [00:08<00:06, 11.63it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  57%|█████▋    | 103/180 [00:08<00:06, 11.67it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  58%|█████▊    | 105/180 [00:09<00:06, 11.15it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  59%|█████▉    | 107/180 [00:09<00:06, 12.09it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  61%|██████    | 109/180 [00:09<00:05, 12.07it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  62%|██████▏   | 111/180 [00:09<00:05, 12.95it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  63%|██████▎   | 113/180 [00:09<00:05, 11.70it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  64%|██████▍   | 115/180 [00:09<00:05, 10.94it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  65%|██████▌   | 117/180 [00:10<00:06, 10.01it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  66%|██████▌   | 119/180 [00:10<00:06,  9.94it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  67%|██████▋   | 121/180 [00:10<00:06,  9.67it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  68%|██████▊   | 122/180 [00:10<00:06,  8.87it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  69%|██████▉   | 124/180 [00:10<00:05,  9.57it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  70%|███████   | 126/180 [00:11<00:04, 11.22it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  71%|███████   | 128/180 [00:11<00:04, 11.25it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  72%|███████▏  | 130/180 [00:11<00:04, 11.62it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  73%|███████▎  | 132/180 [00:11<00:04, 11.81it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  74%|███████▍  | 134/180 [00:11<00:04, 11.18it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  76%|███████▌  | 136/180 [00:12<00:04, 10.30it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  77%|███████▋  | 138/180 [00:12<00:03, 10.58it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  78%|███████▊  | 140/180 [00:12<00:03, 10.64it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  79%|███████▉  | 142/180 [00:12<00:03, 10.51it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  80%|████████  | 144/180 [00:12<00:03,  9.97it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  81%|████████  | 146/180 [00:12<00:03, 10.34it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  82%|████████▏ | 148/180 [00:13<00:03,  9.49it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  83%|████████▎ | 150/180 [00:13<00:03,  9.97it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  84%|████████▍ | 152/180 [00:13<00:02,  9.41it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  85%|████████▌ | 153/180 [00:13<00:02,  9.09it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  86%|████████▌ | 154/180 [00:13<00:02,  9.11it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  87%|████████▋ | 156/180 [00:14<00:02,  9.92it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  87%|████████▋ | 157/180 [00:14<00:02,  9.55it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  88%|████████▊ | 158/180 [00:14<00:02,  8.73it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  89%|████████▉ | 160/180 [00:14<00:02,  9.01it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  89%|████████▉ | 161/180 [00:14<00:02,  9.18it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  91%|█████████ | 163/180 [00:14<00:01, 10.00it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  92%|█████████▏| 165/180 [00:14<00:01, 10.07it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  93%|█████████▎| 167/180 [00:15<00:01, 10.01it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  94%|█████████▍| 169/180 [00:15<00:01, 10.79it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  95%|█████████▌| 171/180 [00:15<00:00, 10.19it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  96%|█████████▌| 173/180 [00:15<00:00,  9.68it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  97%|█████████▋| 175/180 [00:15<00:00, 10.29it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  98%|█████████▊| 177/180 [00:16<00:00, 10.58it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups:  99%|█████████▉| 179/180 [00:16<00:00, 10.28it/s]/Users/taniyashuba/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Processing groups: 100%|██████████| 180/180 [00:16<00:00, 10.96it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;31mTypeError\u001B[0m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/87/d35_l8056xbbpvj6g4knhvsm0000gn/T/ipykernel_70093/1966752516.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[0;32m--> 189\u001B[0;31m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msystem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'pip install catboost'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    190\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msystem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'pip install pymorphy2'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    191\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msystem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'pip install transformers'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    192\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/utils/_set_output.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    311\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mwraps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    312\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 313\u001B[0;31m         \u001B[0mdata_to_wrap\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    314\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_to_wrap\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    315\u001B[0m             \u001B[0;31m# only wrap the first output for cross decomposition\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    316\u001B[0m             return_tuple = (\n",
      "\u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m   1094\u001B[0m                 )\n\u001B[1;32m   1095\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1096\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0my\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1097\u001B[0m             \u001B[0;31m# fit method of arity 1 (unsupervised transformation)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1098\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1099\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1100\u001B[0m             \u001B[0;31m# fit method of arity 2 (supervised transformation)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1101\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    872\u001B[0m             \u001B[0mFitted\u001B[0m \u001B[0mscaler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    873\u001B[0m         \"\"\"\n\u001B[1;32m    874\u001B[0m         \u001B[0;31m# Reset internal state before fitting\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    875\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 876\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpartial_fit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1469\u001B[0m                 skip_parameter_validation=(\n\u001B[1;32m   1470\u001B[0m                     \u001B[0mprefer_skip_nested_validation\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mglobal_skip_validation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1471\u001B[0m                 )\n\u001B[1;32m   1472\u001B[0m             ):\n\u001B[0;32m-> 1473\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfit_method\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    908\u001B[0m         \u001B[0mself\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    909\u001B[0m             \u001B[0mFitted\u001B[0m \u001B[0mscaler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    910\u001B[0m         \"\"\"\n\u001B[1;32m    911\u001B[0m         \u001B[0mfirst_call\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"n_samples_seen_\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 912\u001B[0;31m         X = self._validate_data(\n\u001B[0m\u001B[1;32m    913\u001B[0m             \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    914\u001B[0m             \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"csr\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"csc\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    915\u001B[0m             \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mFLOAT_DTYPES\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[1;32m    629\u001B[0m                 \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    630\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    631\u001B[0m                 \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    632\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mno_val_y\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 633\u001B[0;31m             \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"X\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    634\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mno_val_y\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    635\u001B[0m             \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_check_y\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    636\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m   1005\u001B[0m                     \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mxp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1006\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1007\u001B[0m                     \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_asarray_with_order\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mxp\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mxp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1008\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mComplexWarning\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mcomplex_warning\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1009\u001B[0;31m                 raise ValueError(\n\u001B[0m\u001B[1;32m   1010\u001B[0m                     \u001B[0;34m\"Complex data not supported\\n{}\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1011\u001B[0m                 ) from complex_warning\n\u001B[1;32m   1012\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/sklearn/utils/_array_api.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(array, dtype, order, copy, xp, device)\u001B[0m\n\u001B[1;32m    742\u001B[0m         \u001B[0;31m# Use NumPy API to support order\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    743\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcopy\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    744\u001B[0m             \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    745\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 746\u001B[0;31m             \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    747\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    748\u001B[0m         \u001B[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    749\u001B[0m         \u001B[0;31m# container that is consistent with the input's namespace.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/VK_ML_Project/venv/lib/python3.9/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, dtype, copy)\u001B[0m\n\u001B[1;32m   2149\u001B[0m     def __array__(\n\u001B[1;32m   2150\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnpt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDTypeLike\u001B[0m \u001B[0;34m|\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mbool_t\u001B[0m \u001B[0;34m|\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2151\u001B[0m     ) -> np.ndarray:\n\u001B[1;32m   2152\u001B[0m         \u001B[0mvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2153\u001B[0;31m         \u001B[0marr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2154\u001B[0m         if (\n\u001B[1;32m   2155\u001B[0m             \u001B[0mastype_is_view\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2156\u001B[0m             \u001B[0;32mand\u001B[0m \u001B[0musing_copy_on_write\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: setting an array element with a sequence."
     ]
    }
   ],
   "execution_count": 167,
   "source": [
    "def vectorize_group(group):\n",
    "    vectorizer = TfidfVectorizer(tokenizer=preprocess_text)\n",
    "    vectors = vectorizer.fit_transform(group['title'])\n",
    "    return vectors\n",
    "\n",
    "grouped = train_data.groupby('group_id')\n",
    "\n",
    "tfidf_train_df = pd.DataFrame()\n",
    "similarity_features_list = []\n",
    "\n",
    "for name, group in tqdm(grouped, desc=\"Processing groups\"):\n",
    "    tfidf_matrix = vectorize_group(group)\n",
    "    group_tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=[f'tfidf_{i}' for i in range(tfidf_matrix.shape[1])], index=group.index)\n",
    "    tfidf_train_df = pd.concat([tfidf_train_df, group_tfidf_df])\n",
    "\n",
    "    cosine_sim_matrix = cosine_similarity(tfidf_matrix)\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=5, metric='cosine').fit(cosine_sim_matrix)\n",
    "    cluster_labels = dbscan.labels_\n",
    "\n",
    "    for k, (idx, row) in enumerate(group.iterrows()):\n",
    "        all_dist = []\n",
    "\n",
    "        for j in range(len(group)):\n",
    "            if k == j:\n",
    "                continue\n",
    "            all_dist.append(cosine_sim_matrix[k, j])\n",
    "\n",
    "        top_15_similarities = sorted(all_dist, reverse=True)[:10]\n",
    "        top_15_similarities.append(cluster_labels[k])\n",
    "\n",
    "        similarity_record = [row['pair_id'], row['group_id'], row['doc_id']] + top_15_similarities\n",
    "        similarity_features_list.append(similarity_record)\n",
    "\n",
    "similarity_columns = ['pair_id', 'group_id', 'doc_id'] + [f'top_{i+1}_similarity' for i in range(11)]\n",
    "similarity_features = pd.DataFrame(similarity_features_list, columns=similarity_columns)\n",
    "\n",
    "tfidf_train_df = tfidf_train_df.fillna(0)\n",
    "similarity_features = similarity_features.fillna(0)\n",
    "\n",
    "enhanced_train_data = train_data.merge(similarity_features, on=['pair_id', 'group_id', 'doc_id'])\n",
    "enhanced_train_data = pd.concat([enhanced_train_data, train_features], axis=1)\n",
    "\n",
    "grouped = test_data.groupby('group_id')\n",
    "\n",
    "tfidf_test_df = pd.DataFrame()\n",
    "similarity_features_list = []\n",
    "\n",
    "for name, group in tqdm(grouped, desc=\"Processing groups\"):\n",
    "    tfidf_matrix = vectorize_group(group)\n",
    "    group_tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=[f'tfidf_{i}' for i in range(tfidf_matrix.shape[1])], index=group.index)\n",
    "    tfidf_test_df = pd.concat([tfidf_test_df, group_tfidf_df])\n",
    "\n",
    "    cosine_sim_matrix = cosine_similarity(tfidf_matrix)\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=5, metric='cosine').fit(cosine_sim_matrix)\n",
    "    cluster_labels = dbscan.labels_\n",
    "\n",
    "    for k, (idx, row) in enumerate(group.iterrows()):\n",
    "        all_dist = []\n",
    "\n",
    "        for j in range(len(group)):\n",
    "            if k == j:\n",
    "                continue\n",
    "            all_dist.append(cosine_sim_matrix[k, j])\n",
    "\n",
    "        top_15_similarities = sorted(all_dist, reverse=True)[:10]\n",
    "        top_15_similarities.append(cluster_labels[k])\n",
    "\n",
    "        similarity_record = [row['pair_id'], row['group_id'], row['doc_id']] + top_15_similarities\n",
    "        similarity_features_list.append(similarity_record)\n",
    "\n",
    "similarity_columns = ['pair_id', 'group_id', 'doc_id'] + [f'top_{i+1}_similarity' for i in range(11)]\n",
    "similarity_features = pd.DataFrame(similarity_features_list, columns=similarity_columns)\n",
    "\n",
    "tfidf_test_df = tfidf_test_df.fillna(0)\n",
    "similarity_features = similarity_features.fillna(0)\n",
    "\n",
    "enhanced_test_data = test_data.merge(similarity_features, on=['pair_id', 'group_id', 'doc_id'])\n",
    "enhanced_test_data = pd.concat([enhanced_test_data, test_features], axis=1)\n",
    "\n",
    "X_test = enhanced_test_data.drop(columns=['doc_id', 'pair_id', 'group_id', 'title', 'title_processed'], axis=1)\n",
    "\n",
    "X_train = enhanced_train_data.drop(columns=['doc_id', 'pair_id', 'group_id', 'target', 'title', 'title_processed'], axis=1)\n",
    "y_train = enhanced_train_data['target']\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_indices, val_indices = next(splitter.split(X_train, y_train, train_groups['group_id']))\n",
    "\n",
    "X_train_split = X_train.iloc[train_indices]\n",
    "y_train_split = y_train.iloc[train_indices]\n",
    "\n",
    "X_val_split = X_train.iloc[val_indices]\n",
    "y_val_split = y_train.iloc[val_indices]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_split)\n",
    "X_val_scaled = scaler.transform(X_val_split)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, features, labels=None):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long) if labels is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is not None:\n",
    "            return self.features[idx], self.labels[idx]\n",
    "        return self.features[idx]\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = X_train_scaled.shape[1]\n",
    "num_classes = 2  # Assuming binary classification\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "# Prepare datasets and dataloaders\n",
    "train_dataset = TextDataset(X_train_scaled, y_train_split.values)\n",
    "val_dataset = TextDataset(X_val_scaled, y_val_split.values)\n",
    "test_dataset = TextDataset(X_test_scaled)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Model, criterion, and optimizer\n",
    "model = SimpleNN(input_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for features, labels in train_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_predictions.extend(predicted.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_f1 = f1_score(val_labels, val_predictions, average='weighted')\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Validation F1-score: {val_f1:.4f}\")\n",
    "\n",
    "# Test predictions\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "with torch.no_grad():\n",
    "    for features in test_loader:\n",
    "        features = features.to(device)\n",
    "        outputs = model(features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Saving predictions\n",
    "submission = test_groups[['pair_id']].copy()\n",
    "submission['target'] = test_predictions\n",
    "submission.to_csv('/content/submission.csv', index=False)\n",
    "\n",
    "print('Файл с предсказаниями создан: submission.csv')\n"
   ],
   "id": "79343a30384dcb92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "222129ec681bae60"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
