{
 "cells": [
  {
   "cell_type": "code",
   "id": "75c54f0b1ad4a1d5",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-26T23:07:25.259705Z",
     "start_time": "2024-05-26T23:07:25.255881Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:07:25.417747Z",
     "start_time": "2024-05-26T23:07:25.332792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загрузка данных\n",
    "train_groups = pd.read_csv('train_groups.csv')\n",
    "test_groups = pd.read_csv('test_groups.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "docs_titles = pd.read_csv('docs_titles.tsv', sep='\\t')"
   ],
   "id": "be5b048880bbb72b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:07:25.438638Z",
     "start_time": "2024-05-26T23:07:25.419755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Объединение заголовков с данными групп\n",
    "train_data = train_groups.merge(docs_titles, on='doc_id')\n",
    "test_data = test_groups.merge(docs_titles, on='doc_id')"
   ],
   "id": "236e225e5c41e542",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:07:25.447191Z",
     "start_time": "2024-05-26T23:07:25.439649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Обработка отсутствующих значений\n",
    "train_data['title'].fillna('', inplace=True)\n",
    "test_data['title'].fillna('', inplace=True)"
   ],
   "id": "729aeb9f93dad5a7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RangoPA\\AppData\\Local\\Temp\\ipykernel_5000\\3265502197.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data['title'].fillna('', inplace=True)\n",
      "C:\\Users\\RangoPA\\AppData\\Local\\Temp\\ipykernel_5000\\3265502197.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data['title'].fillna('', inplace=True)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:07:33.850814Z",
     "start_time": "2024-05-26T23:07:25.448197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загрузка данных для NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('russian')) | set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer(\"russian\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  # Удаление HTML-тегов\n",
    "    text = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', text.lower())  # Удаление спецсимволов\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stop_words and not token.isdigit()]\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "train_data['title_processed'] = train_data['title'].apply(preprocess_text)\n",
    "test_data['title_processed'] = test_data['title'].apply(preprocess_text)"
   ],
   "id": "bcaff88ccc5f1e03",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RangoPA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RangoPA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\RangoPA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4b0a0fa86e0f709e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:12:39.849378Z",
     "start_time": "2024-05-26T23:07:33.851823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Определите устройство (CPU или CUDA)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Загрузите токенайзер и модель на устройство\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze().cpu()\n",
    "\n",
    "train_data['title_embeddings'] = train_data['title'].apply(lambda x: get_bert_embeddings(x).numpy())\n",
    "test_data['title_embeddings'] = test_data['title'].apply(lambda x: get_bert_embeddings(x).numpy())\n",
    "\n",
    "def embeddings_to_features(data, column_prefix):\n",
    "    embeddings = np.stack(data[column_prefix + '_embeddings'].values)\n",
    "    feature_names = [f\"{column_prefix}_embedding_{i}\" for i in range(embeddings.shape[1])]\n",
    "    features_df = pd.DataFrame(embeddings, columns=feature_names, index=data.index)\n",
    "    return features_df\n",
    "\n",
    "train_features = embeddings_to_features(train_data, 'title')\n",
    "test_features = embeddings_to_features(test_data, 'title')"
   ],
   "id": "f06380afffc1f1e0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RangoPA\\IdeaProjects\\VK_ML_Project\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:12:39.941080Z",
     "start_time": "2024-05-26T23:12:39.851384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Новые признаки\n",
    "def add_new_features(data):\n",
    "    # Длина заголовка\n",
    "    data['title_length'] = data['title'].apply(lambda x: len(x.split()))\n",
    "    # Количество уникальных слов\n",
    "    data['unique_words'] = data['title'].apply(lambda x: len(set(x.split())))\n",
    "    return data\n",
    "\n",
    "train_data = add_new_features(train_data)\n",
    "test_data = add_new_features(test_data)"
   ],
   "id": "595321c9bc4383be",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:12:40.231571Z",
     "start_time": "2024-05-26T23:12:39.941080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TF-IDF Векторизация\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(train_data['title']).toarray()\n",
    "tfidf_test = tfidf_vectorizer.transform(test_data['title']).toarray()\n",
    "\n",
    "tfidf_train_df = pd.DataFrame(tfidf_train, columns=[f'tfidf_{i}' for i in range(tfidf_train.shape[1])], index=train_data.index)\n",
    "tfidf_test_df = pd.DataFrame(tfidf_test, columns=[f'tfidf_{i}' for i in range(tfidf_test.shape[1])], index=test_data.index)"
   ],
   "id": "2ebaf9b1e70eefee",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:12:40.415567Z",
     "start_time": "2024-05-26T23:12:40.232579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Объединение всех признаков\n",
    "train_features = pd.concat([train_features, tfidf_train_df, train_data[['title_length', 'unique_words']]], axis=1)\n",
    "test_features = pd.concat([test_features, tfidf_test_df, test_data[['title_length', 'unique_words']]], axis=1)"
   ],
   "id": "1a103f1e4966e057",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:12:40.419786Z",
     "start_time": "2024-05-26T23:12:40.416625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Подготовка данных для обучения\n",
    "X_train = train_features\n",
    "y_train = train_data['target']\n",
    "X_test = test_features"
   ],
   "id": "c4a4314a2546c42",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:12:40.451845Z",
     "start_time": "2024-05-26T23:12:40.420841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Разбиение данных на обучающую и тестовую выборки\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_indices, val_indices = next(splitter.split(X_train, y_train, train_groups['group_id']))\n",
    "\n",
    "X_train_split = X_train.iloc[train_indices]\n",
    "y_train_split = y_train.iloc[train_indices]\n",
    "\n",
    "X_val_split = X_train.iloc[val_indices]\n",
    "y_val_split = y_train.iloc[val_indices]"
   ],
   "id": "678d967c006c98c1",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:12:40.645485Z",
     "start_time": "2024-05-26T23:12:40.453858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Скейлинг данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_split)\n",
    "X_val_scaled = scaler.transform(X_val_split)\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, features, labels=None):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long) if labels is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is not None:\n",
    "            return self.features[idx], self.labels[idx]\n",
    "        return self.features[idx]"
   ],
   "id": "5b216e0a496f900f",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:12:40.658403Z",
     "start_time": "2024-05-26T23:12:40.646491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Создание DataLoader'ов\n",
    "batch_size = 32\n",
    "train_dataset = TextDataset(X_train_scaled, y_train_split.values)\n",
    "val_dataset = TextDataset(X_val_scaled, y_val_split.values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "acd6fd61fa9bb24a",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:12:40.664526Z",
     "start_time": "2024-05-26T23:12:40.659411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Определение модели\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ],
   "id": "eaec25e7d15229ac",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:12:40.674915Z",
     "start_time": "2024-05-26T23:12:40.665536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Определение параметров модели\n",
    "input_size = X_train_scaled.shape[1]\n",
    "num_classes = 2\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "\n",
    "model = SimpleNN(input_size, num_classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "id": "77aa5d4d7a76e5ec",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:12:54.985228Z",
     "start_time": "2024-05-26T23:12:40.675924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Обучение модели\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for features, labels in train_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_predictions.extend(predicted.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_f1 = f1_score(val_labels, val_predictions)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation F1-score: {val_f1:.4f}\")"
   ],
   "id": "74e3544581f6a5ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Validation F1-score: 0.2965\n",
      "Epoch [2/20], Validation F1-score: 0.3241\n",
      "Epoch [3/20], Validation F1-score: 0.3268\n",
      "Epoch [4/20], Validation F1-score: 0.3224\n",
      "Epoch [5/20], Validation F1-score: 0.2790\n",
      "Epoch [6/20], Validation F1-score: 0.3430\n",
      "Epoch [7/20], Validation F1-score: 0.3446\n",
      "Epoch [8/20], Validation F1-score: 0.2987\n",
      "Epoch [9/20], Validation F1-score: 0.3446\n",
      "Epoch [10/20], Validation F1-score: 0.3215\n",
      "Epoch [11/20], Validation F1-score: 0.3192\n",
      "Epoch [12/20], Validation F1-score: 0.3298\n",
      "Epoch [13/20], Validation F1-score: 0.3176\n",
      "Epoch [14/20], Validation F1-score: 0.3252\n",
      "Epoch [15/20], Validation F1-score: 0.3086\n",
      "Epoch [16/20], Validation F1-score: 0.3257\n",
      "Epoch [17/20], Validation F1-score: 0.3190\n",
      "Epoch [18/20], Validation F1-score: 0.3049\n",
      "Epoch [19/20], Validation F1-score: 0.2949\n",
      "Epoch [20/20], Validation F1-score: 0.2631\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:12:55.528992Z",
     "start_time": "2024-05-26T23:12:54.986313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Предсказание на тестовом наборе\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "test_dataset = TextDataset(X_test_scaled)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "with torch.no_grad():\n",
    "    for features in test_loader:\n",
    "        features = features.to(device)\n",
    "        outputs = model(features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_predictions.extend(predicted.cpu().numpy())"
   ],
   "id": "3a7413779e14c496",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:12:56.068237Z",
     "start_time": "2024-05-26T23:12:55.530719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Сохранение результатов\n",
    "submission = test_groups[['pair_id']].copy()\n",
    "submission['target'] = test_predictions\n",
    "submission.to_csv('/mnt/data/submission.csv', index=False)\n",
    "\n",
    "print('Файл с предсказаниями создан: submission.csv')"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (16551) does not match length of index (16627)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Сохранение результатов\u001B[39;00m\n\u001B[0;32m      2\u001B[0m submission \u001B[38;5;241m=\u001B[39m test_groups[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpair_id\u001B[39m\u001B[38;5;124m'\u001B[39m]]\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m----> 3\u001B[0m \u001B[43msubmission\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtarget\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m test_predictions\n\u001B[0;32m      4\u001B[0m submission\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/mnt/data/submission.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mФайл с предсказаниями создан: submission.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\IdeaProjects\\VK_ML_Project\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4311\u001B[0m, in \u001B[0;36mDataFrame.__setitem__\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   4308\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setitem_array([key], value)\n\u001B[0;32m   4309\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   4310\u001B[0m     \u001B[38;5;66;03m# set column\u001B[39;00m\n\u001B[1;32m-> 4311\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_set_item\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\IdeaProjects\\VK_ML_Project\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4524\u001B[0m, in \u001B[0;36mDataFrame._set_item\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   4514\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_set_item\u001B[39m(\u001B[38;5;28mself\u001B[39m, key, value) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   4515\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4516\u001B[0m \u001B[38;5;124;03m    Add series to DataFrame in specified column.\u001B[39;00m\n\u001B[0;32m   4517\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4522\u001B[0m \u001B[38;5;124;03m    ensure homogeneity.\u001B[39;00m\n\u001B[0;32m   4523\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4524\u001B[0m     value, refs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sanitize_column\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4526\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   4527\u001B[0m         key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\n\u001B[0;32m   4528\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m value\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   4529\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value\u001B[38;5;241m.\u001B[39mdtype, ExtensionDtype)\n\u001B[0;32m   4530\u001B[0m     ):\n\u001B[0;32m   4531\u001B[0m         \u001B[38;5;66;03m# broadcast across multiple columns if necessary\u001B[39;00m\n\u001B[0;32m   4532\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mis_unique \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns, MultiIndex):\n",
      "File \u001B[1;32m~\\IdeaProjects\\VK_ML_Project\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:5266\u001B[0m, in \u001B[0;36mDataFrame._sanitize_column\u001B[1;34m(self, value)\u001B[0m\n\u001B[0;32m   5263\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _reindex_for_setitem(value, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex)\n\u001B[0;32m   5265\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_list_like(value):\n\u001B[1;32m-> 5266\u001B[0m     \u001B[43mcom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequire_length_match\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5267\u001B[0m arr \u001B[38;5;241m=\u001B[39m sanitize_array(value, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, allow_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m   5268\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   5269\u001B[0m     \u001B[38;5;28misinstance\u001B[39m(value, Index)\n\u001B[0;32m   5270\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m value\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobject\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5273\u001B[0m     \u001B[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001B[39;00m\n\u001B[0;32m   5274\u001B[0m     \u001B[38;5;66;03m# this deprecation\u001B[39;00m\n",
      "File \u001B[1;32m~\\IdeaProjects\\VK_ML_Project\\.venv\\Lib\\site-packages\\pandas\\core\\common.py:573\u001B[0m, in \u001B[0;36mrequire_length_match\u001B[1;34m(data, index)\u001B[0m\n\u001B[0;32m    569\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    570\u001B[0m \u001B[38;5;124;03mCheck the length of data matches the length of the index.\u001B[39;00m\n\u001B[0;32m    571\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    572\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(index):\n\u001B[1;32m--> 573\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    574\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLength of values \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    575\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(data)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    576\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdoes not match length of index \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    577\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(index)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    578\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Length of values (16551) does not match length of index (16627)"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
